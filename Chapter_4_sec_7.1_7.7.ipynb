{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.7 Lab: Classification Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7.1 The Stock Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import math\n",
    "from patsy import dmatrices\n",
    "import statsmodels.discrete.discrete_model as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sma\n",
    "from statsmodels.graphics.regressionplots import *\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.naive_bayes import GaussianNB as NB\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "sns.set_style(\"ticks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Smarket = pd.read_csv('https://raw.githubusercontent.com/tvanzyl/Sharing_ISL_python/master/data/Smarket.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>5.010</td>\n",
       "      <td>1.1913</td>\n",
       "      <td>0.959</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>1.2965</td>\n",
       "      <td>1.032</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>1.4112</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>1.2760</td>\n",
       "      <td>0.614</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.614</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>1.2057</td>\n",
       "      <td>0.213</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year   Lag1   Lag2   Lag3   Lag4   Lag5  Volume  Today Direction\n",
       "0  2001  0.381 -0.192 -2.624 -1.055  5.010  1.1913  0.959        Up\n",
       "1  2001  0.959  0.381 -0.192 -2.624 -1.055  1.2965  1.032        Up\n",
       "2  2001  1.032  0.959  0.381 -0.192 -2.624  1.4112 -0.623      Down\n",
       "3  2001 -0.623  1.032  0.959  0.381 -0.192  1.2760  0.614        Up\n",
       "4  2001  0.614 -0.623  1.032  0.959  0.381  1.2057  0.213        Up"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Smarket.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Lag1', 'Lag2', 'Lag3', 'Lag4', 'Lag5', 'Volume', 'Today',\n",
       "       'Direction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Smarket.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1250, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Smarket.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.029700</td>\n",
       "      <td>0.030596</td>\n",
       "      <td>0.033195</td>\n",
       "      <td>0.035689</td>\n",
       "      <td>0.029788</td>\n",
       "      <td>0.539006</td>\n",
       "      <td>0.030095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag1</th>\n",
       "      <td>0.029700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.026294</td>\n",
       "      <td>-0.010803</td>\n",
       "      <td>-0.002986</td>\n",
       "      <td>-0.005675</td>\n",
       "      <td>0.040910</td>\n",
       "      <td>-0.026155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag2</th>\n",
       "      <td>0.030596</td>\n",
       "      <td>-0.026294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025897</td>\n",
       "      <td>-0.010854</td>\n",
       "      <td>-0.003558</td>\n",
       "      <td>-0.043383</td>\n",
       "      <td>-0.010250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag3</th>\n",
       "      <td>0.033195</td>\n",
       "      <td>-0.010803</td>\n",
       "      <td>-0.025897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.024051</td>\n",
       "      <td>-0.018808</td>\n",
       "      <td>-0.041824</td>\n",
       "      <td>-0.002448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag4</th>\n",
       "      <td>0.035689</td>\n",
       "      <td>-0.002986</td>\n",
       "      <td>-0.010854</td>\n",
       "      <td>-0.024051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.027084</td>\n",
       "      <td>-0.048414</td>\n",
       "      <td>-0.006900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag5</th>\n",
       "      <td>0.029788</td>\n",
       "      <td>-0.005675</td>\n",
       "      <td>-0.003558</td>\n",
       "      <td>-0.018808</td>\n",
       "      <td>-0.027084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.022002</td>\n",
       "      <td>-0.034860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume</th>\n",
       "      <td>0.539006</td>\n",
       "      <td>0.040910</td>\n",
       "      <td>-0.043383</td>\n",
       "      <td>-0.041824</td>\n",
       "      <td>-0.048414</td>\n",
       "      <td>-0.022002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Today</th>\n",
       "      <td>0.030095</td>\n",
       "      <td>-0.026155</td>\n",
       "      <td>-0.010250</td>\n",
       "      <td>-0.002448</td>\n",
       "      <td>-0.006900</td>\n",
       "      <td>-0.034860</td>\n",
       "      <td>0.014592</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Year      Lag1      Lag2      Lag3      Lag4      Lag5    Volume  \\\n",
       "Year    1.000000  0.029700  0.030596  0.033195  0.035689  0.029788  0.539006   \n",
       "Lag1    0.029700  1.000000 -0.026294 -0.010803 -0.002986 -0.005675  0.040910   \n",
       "Lag2    0.030596 -0.026294  1.000000 -0.025897 -0.010854 -0.003558 -0.043383   \n",
       "Lag3    0.033195 -0.010803 -0.025897  1.000000 -0.024051 -0.018808 -0.041824   \n",
       "Lag4    0.035689 -0.002986 -0.010854 -0.024051  1.000000 -0.027084 -0.048414   \n",
       "Lag5    0.029788 -0.005675 -0.003558 -0.018808 -0.027084  1.000000 -0.022002   \n",
       "Volume  0.539006  0.040910 -0.043383 -0.041824 -0.048414 -0.022002  1.000000   \n",
       "Today   0.030095 -0.026155 -0.010250 -0.002448 -0.006900 -0.034860  0.014592   \n",
       "\n",
       "           Today  \n",
       "Year    0.030095  \n",
       "Lag1   -0.026155  \n",
       "Lag2   -0.010250  \n",
       "Lag3   -0.002448  \n",
       "Lag4   -0.006900  \n",
       "Lag5   -0.034860  \n",
       "Volume  0.014592  \n",
       "Today   1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for panda data frame, there is a method corr to compute pairwise correlation between numerical variables\n",
    "Smarket.corr()\n",
    "# as one would expect, the correlations between the lag variables and today’s returns are close to zero. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD7CAYAAABgzo9kAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABNbElEQVR4nO2deXgURfrHvz2TmxASIJCEICByrggKiyIqigioaGAVZQVFV3FdUFZ/Kl4oIupuWK8VcFHcA110lV0vDhEBXQEP1PUAueUMJFwBQoCEZKZ/f8xUT3V39TXTkznyfp6Hh0mfb3V3vfXWW2+9JcmyLIMgCIJIOjyxFoAgCIKIDqTgCYIgkhRS8ARBEEkKKXiCIIgkhRQ8QRBEkpISawEAoKamBuvWrUN+fj68Xm+sxSEIgkgIfD4fDhw4gDPPPBMZGRm6/XGh4NetW4fRo0fHWgyCIIiEZN68eejTp49ue1wo+Pz8fAABIQsKCmIsDUEQRGJQUVGB0aNHKzpUS1woeOaWKSgoQHFxcYylIQiCSCyMXNs0yEoQBJGkkIInCIJIUkjBEwRBJCmk4AmCIJIUUvAEQRBJCil4giCIJIUUPEEQRBi88K//4TdPLo21GKbERRw8QRBEorH8692xFsESsuAJgiCSFFLwBEEQSQopeIIgiCSFFDxBEESSQgqeIAgiSSEFTxAEkaTYCpMcP348ysrK4PF4kJWVhUcffRTdunVTHePz+fDkk09i5cqVkCQJt99+O0aOHBkVoQmCIAhrbCn40tJSNG3aFACwbNkyPPzww3j33XdVxyxYsAC7du3C0qVLceTIEQwfPhz9+vWj/O4EQRAxwpaLhil3AKiuroYkSbpjFi9ejJEjR8Lj8aB58+YYNGgQlixZ4p6kBEEQhCNsz2R95JFHsHr1asiyjFdffVW3v7y8HEVFRcrfhYWFqKio0B1XVVWFqqoq1TbRcQRBEERk2FbwTz31FADgvffew/Tp0zFnzpywbjh37lzMnDkzrHMJgiAI+zjORTN8+HA89thjOHz4MPLy8pTthYWF2Lt3L8466ywAeoueMXbsWIwYMUK1jS0cSxAEQbiHpYI/fvw4qqqqUFhYCABYsWIFmjVrhtzcXNVxQ4cOxfz58zF48GAcOXIEy5Ytw7x583TXy8nJQU5OjjvSEwRBEIZYKviTJ0/i97//PU6ePAmPx4NmzZph9uzZkCQJ48aNw8SJE9GjRw+UlJTghx9+wODBgwEAEyZMQNu2baNeAIIgCEKMpYJv2bIl3n77beE+3g/v9XoxdepU9yQjCIIgIoJmshIEQSQppOAJgiCSFFLwBEEQSQopeIIgiCSFFDxBEESSQgqeIAgiSSEFTxAEkaSQgicIgkhSSMETBEFEiM8v48MvdqDe54+1KCpIwRNhsXFHZdx9zAQRK5at2YmX/v0D3v10a6xFUUEKnnDMzvIq3D9jJf6+8KdYi0IQcUHV8VMAgOMn62IsiRpS8IRjjh6vBQBs31NlcSRBNA78sgwA8Hj0q93FElLwBEEQEeIPeis9guVMYwkpeIIgiAiRBRa8LMs4Wl0bK5EAkIInwiD4LRMEEcTvD1QKSZJQceg46up9WLByG8ZMWYK9B6pjJpfjJfsIgiDimcPHauD3y2jRLLPB7sl88PU+P8Y9vQwXnd0Gh47WAAAOVdWgKD+7wWThIQueIIik4qbHP8LNTyxt0HuyXi1z1Xy5thw1p+oBABlp3gaVhYcUPEEQRITwLhoAOFXvR02tDwCQlkoKnkgg5i/fHGsRCCKuYC4aPoaGWfCxhBQ84ZgfthwEAMRZRBhBxAym4HkNX3sqYMEjhkEJpOAJgiAiJKTfQxqeKX1/DMPOSMETBEFECPPB8/gE2x6f8wXuf/GzhhAJAIVJEgRBRIzig+dcNEzp8wb8txv3N6RYZMETzqit88VaBIKIO5QoGsE2kYvG55fx2Muf48etB6IqFyl4whHXPrgw1iIQRNyhuGg4E15x0Qhc8FXHa/Hd5gOY/vo3UZWLFDxBEEQEnKipM03fIQs0PBuMjfb4q6UP/vDhw5g0aRJ27dqFtLQ0tGvXDk888QSaN2+uOm7GjBl444030KpVKwDAOeecgylTpkRHaoIgiDjh/174L7q0C+hDUeiwSImz42Ku4CVJwm233YZzzz0XAFBaWopnnnkGTz/9tO7Y4cOH44EHHnBfSoIgiDhlz4Hj6HRaHgC1D54hm2rx6Gp4SxdNbm6uotwBoFevXti7d29UhSIIgkgk5GA+eFG4pEiFN1RovKMwSb/fjzfffBMDBw4U7l+0aBFWrVqF/Px83HXXXTj77LN1x1RVVaGqSr0SUEVFhRMxCIIg4goWKbN7vz41sCxYuphZ9TF30fBMmzYNWVlZGDNmjG7fqFGjcMcddyA1NRWrV6/G+PHjsXjxYuTl5amOmzt3LmbOnBmZ1ARBEHEEU/Arv9+j2ycaZGXHR9uQt63gS0tLsXPnTsyePRsej96zk5+fr/zu378/CgsLsWXLFvTt21d13NixYzFixAjVtoqKCowePdqp7ARBEHGByDXDEFnpyrYom/C2FPzzzz+PdevW4ZVXXkFaWprwmH379qF169YAgA0bNmDPnj3o0KGD7ricnBzk5OREIDJBEER8YT6QCmzaWYljJ+qUv+PGgt+yZQtmz56N9u3bY9SoUQCA4uJizJo1C+PGjcPEiRPRo0cPPPfcc/jpp5/g8XiQmpqK6dOnq6x6giCIZMUv8LMr+2QZ9724SrUttEBIFIWCDQXfqVMnbNq0Sbhvzpw5yu/S0lL3pCISAkoXTCQD9b6Adk7xhj/v0zRjpGCXmUvHTWgmKxE2Hhc1/I9bD+B3pctxinLdEA3IrooqjJi0ALdMi2yJPzMFLxpkDbl0YhwHTxBGeDzuKfhX3l2Lsv3V2HvwuGvXJAgrJvzpEwDAkWO1EV1HNhtkFbhvfIJMk9GAFDwRNl5BNBVBJApWA6NOMLPgd+8/pts2fvqKgAyuSSCGaigRNqTfiXjnZK3xuqjh6HefX8banw86utbL7651VQYnUBUlwsZNFw1BuM2a9RW47uFF2LijUrg/HN36nxVb8PBLq/HDFnUed9HqTae3aWZ9wShreFLwRNi4OchKNF58Pn/YPvCtZUdw61Mfo/rEKd2+7zYFVk/avOuw+OQwlOueA4FUBAcOn1RtF0XFZGXEfsE8UvANABup31d5ItaiuAopeMINXn53LW58fImpO8WIfy3dhP2VJ7Bu2yHdPmUhbIPvNJxIRW+w16q12EX+/BQbPkzywScBH6/ZhXqfH7c99TH2J5GSj91a8UQy8fnaQHbamlPOFTxDZIwzg+pEbZ1+Z+Asx/fxBmPl/ZqZTaL7e73WBhD54JOM7zZHdw3GhsR0ckeYuBnZQCQGiqUtzKZu+yoA1K6SbzbsAwD888ONwjMiseDrfeqTfYLv1l6UGfngk4qk8mq4+G0adaMJwgztykhOjI5wjAlmlft0FrxAwZMF3zjglVcyqTHRDD2CcErIV+78XK1hYJYCYNPOStTVczOlw7LgAyrTp7HgRfe1k/qAfPBJRjIZquRNIeINIwt+z4Fq3PfiSsx5f53lsWYYD7IaHxtLSME3OLF/6W5B/nLCHSL/jv4w92sAxhZ8VXUgjHLbnqMR3SfkotFY8GG6aCgOPslIptmfpN8JN7AKZ7TLsROnDAdOmQKWVNuc3yPkolH74MlF04iRTP5KZEjBE24SaY/whkc/1CleBhsUVTUiYdxPGdTVbBcpeDszvWmQNQngv6k4cMu5RjTCJInGRyRfkdbo32CQlkCkgCO6r/Za5IMnACTXKCtBuEg49oI2dv74SfGkpuff/J9uWziLbigyaqqxyNjp3bW14+u7DSn4BiaZ1DsNshKuoKxPGvn3dLxGrOArq8LP9/6vjzeF8tkovnx1TdamIXnhngFo3TzL8trRtvdIwTcwyWTAR0O/U5vR+JB1PxygqU81tfZXBLPrYpy3ZCPu/fNnAOyLmJJiT7XmNEmzecXwiH26s0ZGZNOx4wuy4Ak3ceNrsspnozKwwrgh++St3OupXo+ty0dbwZMF3wCoZrIm0RN3U78nU8+GcAb7jtwwGJxkpDS62/7KE3jlvbXw+WWdn15xI1l8sClejy1TLtopOpJI3cQv/DtMRAu+sqoGj/xlNaqOq3NuU6oCwh3C/460tYkpeCPLmFeo2gblWDCnfOnrX2PBym3Yvueo3o1jU9SUFI+tAbdwBnqdQAq+oUk8/Y53P92KH7cexLI1u1TbyUNDuElYUTQaC5j54G1NMtLc74ZHPwQAHD8ZaCTSUj2GClhkeLcvzFF+p6Z4bK2XQAo+yUhA/a58hNqJG04r5Ev/+QHPzvvWLbGIJCHkonF+rpEFb2eQ0+h+tXWBRiI1xavPORP8X5tsDAAGnFOs/LbTwADRn0tCCr6BScS0uEzBL/9aY8E77Fp/+PkOfPq/MtNjaOC28eKGy48p+FSDPDDqiazi+9UGB2plWeCDD57zr483qbafXtQM1w7spPyd4vUY1vWLe4cagnBWsXICKfgGJgH1u7KYwY7yKtX2qIRJun9JIs6JKExSA0sHnJritX9fDSeDbh6fX7ZtYWekq++X4pUM63pB8ybK76PVp3T1yk1IwTcwiWigGvkJf9p2CLP+/YO7N0vA50NEhuKiCedkjRI9VR/IOZNia7EN/R1ffX8d6oP5bA4eOYmFq7bbEoO5ZK7s3yEgliQZ+uBTNe6jnVFU8JZx8IcPH8akSZOwa9cupKWloV27dnjiiSfQvHlz1XE+nw9PPvkkVq5cCUmScPvtt2PkyJFREzyRMBu5TwTMBoKWfLEDE67tGfE9WHQR5bdphLj4zk/UBFweWRmpwv18FJvotu9/9rPye/rr36Bak/rAqC6wvDO/HdEDvx3RAwCQkSbuRWj982mp0bOzLa8sSRJuu+02fPTRR1iwYAHatm2LZ555RnfcggULsGvXLixduhRvvfUWZsyYgbIyc39rYyHCuRWmvLl0EybNWOnyVdX8JFixniDcgtWJcIwffS6aQKhjk0yxglff1/x+Naf0s2KNRGRrLUuSpBh0meli+1lrwdtxJ4WLpYLPzc3Fueeeq/zdq1cv7N27V3fc4sWLMXLkSHg8HjRv3hyDBg3CkiVLdMdVVVWhrKxM9a+ioiLCYiQOblvwb3y00TCDnlvsPXg8qtfnScQeDhEZkbxyrReE+c+bGFnwDrIF1wtSDzvpYXoNImm0C4FEM+uko1QFfr8fb775JgYOHKjbV15ejqKiIuXvwsJCoeKeO3cuZs6cGYaoyQHpL3Po8TRe3Kwbtiz4MG7ohgvRq1n1RxuK6SaOFPy0adOQlZWFMWPGhH3DsWPHYsSIEaptFRUVGD16dNjXjHtshGYRQejxNEIiyCZpYPw2ybBWbeFURTeqL7PYm2Wn4Wj1KcNFStzAtne/tLQUO3fuxAsvvACPYN25wsJCleumvLwcBQUFuuNycnJQXFys+ic6LllJZP3uVojn0Wrj1K2J/HyICHHx3XvCjKKxPEdjbf9xwgUAgD9NvND2NdiEwbTUgO+9PooWvC0F//zzz2PdunWYNWsW0tLEOR6GDh2K+fPnw+/3o7KyEsuWLcOQIUNcFTZRUY/cJ64Gc2uS1iN/WW24j/LbND4iCZO0+iL59AG6+4ZxP62L5hent8CCZ0vQtV1z4fF/nXyZbhuz4FkYZUwt+C1btmD27NnYv38/Ro0ahZKSEkyYMAEAMG7cOKxduxYAUFJSguLiYgwePBjXXXcdJkyYgLZt20ZN8ERCNbATOzEixk5uDSM27QwNBO+sOGZ4XAK3f0SYRBJFY3QGM6q06TUiWZJ1+96jWPz5DkfntMrTL/rBBlmZoq8XpD1wC0tHVadOnbBp0ybhvjlz5ii/vV4vpk6d6p5kDcir769Dp7a5qlwS0SKRLfhIBvt376u2dVwiP59oUlfvx68eWIA7RvTAlRecHvZ1Xn1/Hfr1KMQvTm/honTuENarNziHKXJthEokvemJz36q+vvlBy91dD5DseA9cWDBNwbe/+xnPNNASbD80XuXcU2W1aCXwWr1RICq44Fxi7eXb4noOu9/9jMenLXKDZHcI4JG3Sobo1kIYqS2RFF+dljnsZ6wYsHH2gdPuEniqrBIQsQsFTzDpcdztLoWBw6fdOdicUBdcAq+dpIM47XF67F+u/mEtHjtHUXiorH6JnWx6HEQ0cYyXTLZyYJPcHgbIsrpn6NKJLmrtbG/Rrg1yDpmyhL85smlrlwrVtT7/Dh0NNBInQqmsDWa1j5/+RY8MNPcMo927vFIcWPQU4vWgucbyFg9jcKWgWRjfFKzaEEKvoGJUyPKFpF8h3aVSyI/H7d55d21uPmJpThRU6fKUa7FjiX63ab9+PzHctdldANF/DDevVMXTV7TDO6+sfnYWuVl4YYhXXH/mN5BOaJ3L1p0uyFI8GRjbmDbvdM4H4+QL9cFFPLJ2nolL0qawEVjp+187JUvXJUtGoQ1xmpwEvvetC4aSQLK9h/D70pXoFPb3DDuGDkSgF8P7oITNSyRGVnwcUXZ/mN486ONtpV1soRJRsLM+d/bOi6WcfB3P/8p7n/xs5jd34zaoIIXrVTktxi5T5SxCFd98MHNWgt+Z3kVfle6AgCwZfcRx/dzBU24cTQDL8iCD4NHZ3+Og0drcEX/DmiWne7o3MZqwe+3qWQifTyyLOPDL3aEde7PZUcju7nLMD0gy6HEV6K5CFZx1E7GIrbvPYr2hTkJs/KYsQUf+J9PzZvXNB3Ha6K7gpITQu+SLPi4orYu/CZXO9WZUBPp0/lp2yH85T8/uiJLvFDv8ysDcSIF79Yg3U/bDmHis5+qcqI3JOE07h2KDGaqMhcNSwuQ4oHX60G6QY72hkTS/IimSiAF38BE61263TPYWVGFq+59H2vWm6dyZvk0RJyoqcMt05Zi40776Yz5cvh8fs5PaQ9RDm/t9Res3IYjx4zz4cQbPr+shNKJDGuzMDsn38W+ykBa6J/3uN+TqTlVrwwUG2FX1tufXobbn15mekxeTmAwNT8vE0BgUpFHAvwWvZ3+PYtM97sBe4essY5mr54UfAOgDpOMzst0e6LWpp2HAQBfWEReZKYbK/iNOw/j4JGTuP9F6wVJeHcEo/T1b3D9I4utheWwqiy7Ko7hlffW4pl53zi6biyp9/kVN4wkmLjjV6x70bnx0WO8/pHFGD99hfL3ydp6/PPDDarEc3YlLT90HOWHAo0R/7qvueQM5ffgc9vhwbG/xNB+7QEEZ41KEnwWDu+cLH2ureEDOtqUzB7M/SX65t2GFHxD4+Bl/n3BT7jnhf/aOvaz7/aEKZCYkHdQLHDL3IBlVNiiiXB/8GTjXTa+6i/WOg/rs7oqmzB07ISznkEsOVpdq6yqJfKMMxeNyG9uZTWLcNv77vfL8Ptl7K88oWxbuGob3lq2GZ98y636Flb63tBJfAipxyOh/1lFyvwLjyTB65GEi3jwaBfjACJPsteyWQaGBddq1VwZQHQDC2iQNSwcvhDu+3Dib3vn063O7uMiVt90btN0nNa6KY6fNFaUZr0VvwyIMrpaKf7qk3VYu/UA+vUQd6WtxjhYZUqQMUQAwKMvf6FY6SJlo/jnBSZ87Sn9oGI0y75o1Ta0btEEfbq1VrZtLTsikCvQ8NRw8smQlfdvpFS3mkS+iHowbH6dJElI8Xqwe59xojtAv14qEHmD9/fHAll1F67erpYt+mOspOAbAj7BkVVIW7xhpG+zM1IhSeG7nPx+WZgnxOpqz877Ft9s2Ie/PnIZWjXXZ+qzOp+JmyhRIoB6Mo9wkFXxz9uz4KNZ8tnvBrLLLni2BM+/+T+s+Ga37XNlGZj9zo9Y/PkOLHi2RHiMtkfLf37paXp1xud9STVYQo9H9E1G7VOR2ELzUbo+GqGLZuPOSlx17/vYWV4V9jWU/NVhvBjmIoh/zL/qe0f3hiRJpgrezBo33GfxTMuD68MauR6segCKhWh+mzjBnrJhFrxIf/lEPngDjeW2L9iJcmc4TcfLi9wmX+8uZN+nxwOkpFi/dZEFHy1CFjwNsrrG6h8Cq059u3F/xNey6zvjjzsVVPDL1uzERpcXy3Yz10hoAEh/zXYFTZHbNB1ejwTZpL0yk+bHrQfF51h87KzLbdSwWNUVttvKKjNbdSqWSBJQWVWDas41ZuaDF4VQxkNOGpEEqggqGzK+8dFG7D0QSEM9ZmhX9OluvDJcVkaq4XoGvNWunUj2i9NbRK23J5EFH+fYfTHccSxp1J/f+h73z7COLmHMeW8t/vRP88iPOhez0tn5pi1dNCa7pr76Jdb8pA/BtH6k5nmFLc9nLhpNXvDlX+9S/l62ZhfGTFmCbVEIF4wUSZIwdupHuJWbvOQzmQRlpMzNlHw03Vd19T4cO3EqdC9uHy9RXZ0PM97+3tRn/ubSTfjqpwpkpntx/WVdhO6V5jkZuPHybphy23mG9WP+H65UfrNUEJf1PQ0Lni3BHydcENUxC0mK7iBrI1bw4T9UdqZd/7Pqww3TRfPBym2WkTLRcP8ILa3g/5G4aICAJbrqhz2qgVqrR8rqsLEFb+WiCf7gKu32vVV44V/fKX9/tynQu7MakOP57Lsy4WCi2zBlc4KbkWlmwRsqeBvfrs8v465nPsE/P9wQhqRiHn35C9zw6Ifi98Rt2rXvGJZ+tRPjp69AyX3vW6RCNtbAkiThukGdUdCiiXCmcma6VxV9o6yTGsUUvir5QGGSrsIqQUNmDOAjO6Lpgz8VRkicMcaWMnt2Xo8k9vEGsep67qs8gdLXvsHzb/6Pu7b+JH4be39GXXiz97pheyUmzQz0mnhrt/rkKdVxit82eExdvR9z3l9rGsHxp39+i3uetxfSaobP58f2vQFFJLIcReVj70CUkdlIkdtx09SeqseO8iq8tWyz5bEiRLNGWbgng5eCF5W3xv2yed6YSCzsAk2YL1Pw/HcdzR6NJEk00clN3HxVtgNiuA9k254jmOTANeMEM2XrFPNJGIGNKSkeHDh8Ah9/tdPgKubybNkdmEy1r/IEF3cvuAq3kcllNHvTTHH997tQzPWGHZXYezDgv9U2ukwpSsHasauiCh98tg2z/v294bWtqDp+Cu98ssWyMr/+4QZMfPZTlO0X9x5E5WOTd8QRNuEr+Eh89bIsK6GQZvDyqcaqNOlA5i/fbPjsTkSQX2bkpZ1VfysWPFe5ozkgL0lkwUeFcJ7pPz/cgK/WhSbf2PWd8asZbS07ig0uD64yrGbpaamt86EiOCNQi9lHzT7IVK8Hp+r9ePHt73H4WI3hcUb8sOVg8DjuQPOeu+I7N5qhafYMtKshvfBmwC2jU/CavC+sux7J5Kg576/F3xeux4tvfW86gMss3GPHxff6SjBuIYqD3773KE7V+YwteJsumnD5bvMB82sH319dfagR4EXS9kaPVp9C2X576/ra5baSM3FhrzaqbenBBVXcNJbMIAveZcyiQ6x4a9lmPPn3NcqXaDvFeYTvz66sTi2uP/xjDcY9vcw8nFGgcRUFzytME1eOFTKgvJg6n18vj8qED/xXb+DqMpuar52UxZ6X1t/Kx8pXnziFJV8EeiiiiUR2YfIu+zowgGt4XFAWOyF9DK0PvrKqBhOf/RSz3/nR0SCr9rFHYsFbRSExC/k/n4gn84nCYEWzTJ1QcpE65YBIibP88arGTXDbv00eHJEs/KXJgo9T7DcSkb1Bu/XMqcXFQkVFFXn99mAvQ3BJpuj4wSmRn9J2GKksIzsjFUBgIhPvkwfU5Wc61igiwskzYNa+kYvG65HwzLxvsSwYYeORJHy7cR+e+vtXjg2ErGD5rGANVIrXY9s1wN7fwSOBlMxMuW7ZfcRQSYufk2x4zIefb7cpjVomI0QNNP9MRe6dFJvLPhpxW8mZaJ4TWtGpzidoRIIfGO8ClDRvolVeppLELGIkKaorIJCCjwCnFny4YzV2Z7+yCnno6Enc9cwnthd60K7q/tO2Q0pOdVERJ/+mLwD1+qDiwVFbt4ffDzRtEkrypMpPopUi+BCnvvqlqnvP0PrmN+2sxE/bDsHvl3Wx9+x5Gbloyg8dV0VveDwSHp/zJb5cV2HZ6J6q82H+8s2KjHbT1DJZRCF/RvBlrqv3K9ZvWqrHsMEzc9Eo4xzcuW8s3WRbHsBawYuCDfgzXnz7O91+NxL18XWwTpD2mzUifNmjGSbpkSibZNwhK/87ezF2F57WYtcqZRV9xTe7saO8CotWbzM93mMwYFlZpfenM4paNkFRy2wAUE39FlY+249Hn7aATxPMX5o/bLUg06XWRXPfiyvx4KxVWLhqG/Zxya4AYwXP7vfq++uUhZEBTWQH1+jyyuyuZz4BAHz81U68tngDHpq1GvOW2F/9i7loTtX5cfCo8XtQnaOK0vJxC3R7I4qi4cczRDltzLBuAAVGC3eOKO2zG5PP+J7mKe69P3/3APx2RA80yQz0tHhLX6vfRSkRwpeHXDSu4mbIk1MLPlwfol1fKFNYmemBD/BkrXmlZK4WM7+1VjHxz4+f9SfqZNh30Zg/S78sY1/lCWzcUanqLj8rSJFs1NvZc0A/QBca6BO7aLTwDR/vv+WP38FSYASf06Zdh/GvjzfZbuyYgv987V7LYz/9NpAKgM9xXlvnw+59gbJWn6jD1Fe/FJ5rp1PIf3dWefa1WDVopwS9L6vv5T6DtNNnFDezLZfagg/JcEbbXAy74HSc0TYX943ujd9dc5b4JIQGYt1AkiSa6OQmrKJH0mqysCynPvhw81wYKfh/r9giPI4peKvwMSWm3GRSx6of1IqGH2jkffAipagV+4bBXYT3kGV95VadKwO3PfUx7p+x0rK7bNRYibYymbUN4fcGESBVx0Px8nyvStvD2rizErPfUa8qxR+hjeZRjpFlHApa7XZ6e8++8T+cqKlTWdp1dX5lgtbeg+IIKQB4bfF6fP7jXtNvmC+X0/qys8I815Nozka4dfKXJikKtPCfzymDgfoB5xSrxkwGn3uaar/Txs5Knpha8KWlpRg4cCC6dOmCzZvFEx5mzJiBfv36oaSkBCUlJZg6darrgrrBF2v3KjnGmUKJxP/l1IJPCdOCN3LRzF20XngcUyBs0Q4jJElswZspUd5Fwisq0SCczpo2uLAvoOFV8O+FV1QbLcpk1FgJJwgFn9d+jevGDioFr7lnmcUM2HaF4mXmNu4Ilc1uFM31jyzG51ze/OM1dZwf3/i8T/9Xhj/M/RpfrjNesctpFA3/zhauMh+UtXLR8Iy5vKvptRwZTtw3eFnf00wODNGiWSYWPFuCOQ8PAgCcVtDU/v0sOF5TjwUrzV2pkWDpTLr00ktx0003YfTo0abHDR8+HA888IBrgkWD7Xv1VkUkrafdxoEdZfUhrt16EO2LctBUs6oMX9GUGG3BIByz5Fg3v9wgxh0IyM6sKCfx87yLhlfw//lkK0ou6qgslQbYjyXeX3nCMIQR0Ic3mqEdMGaI3pU/+JyOhOHb5Z+ZtgEWzbpcxOUCN1KcB46EGppUr/21Q/mFUSY++2noPjYev9l4i/b9zV20HsMu6IAWzcQRJE7ag7U/65PNGbkqTmttrlCdKHj29c687xLDhtaIghZN8McJFxivAxuHWCr4Pn36NIQcDYKqjsuq/8K7nu37Bo5MSzGutHX1Pjz8l9Xo2i4Pf5p4kWrfTVM/Un6PnfoRvF4J/wguIsBj5FPm2bijElUnTqGam7SztewIcpumIyM4eKQNC+PhG5Y0javhwJGTKgVvpjy06BS8Kj2B7cs4suAPHq3BjVOWhKXg/SoLXn1xq5S3Rgqe7/pHGvMN2Etdwb5Nn1/WDepq3W7/XrEFW3cfwbQ7zhdeK9IslUY9VatxM97QePHei01dk8ps3zAf7y9ObxHeiTHCNR/8okWLcNVVV+E3v/kNvvtOH+LEqKqqQllZmepfRYX5ws5uwVsIyq8GcNEwMjOM29PaYJfVKsHVkepaxU+rhVUQPsb4xbe+Cw38Abh/xkpM++tXOHQ0FEJZ+to3eO4Ndey5EWoXjbrBqtbM9OR7EI/eeq4jRc0rC6PETxf3LsbO8irVMzNSEht2iJNVhaPcAXUop9MZxKLwTkAbpRMqxxO393MoXQA73ydT4vOWbMC8JRsBAMu/3o3yg8eFPbBIkstZymLw7qwmmGVwIagdipqZKmHtgtfxQrRCJV2J9xk1ahTuuOMOpKamYvXq1Rg/fjwWL16MvLw83bFz587FzJkz3bitYyKK5BNez9nZbPBTBKv02nzURjz68ue6bayC1HEV8+M1u/D9lgOWM+82sIlNgKl1w1c2rZWprfy8wu/bvcBR+l1eZxrlNEn1enBnMCwRAG4f3sOwMWCRJW4xd9F6XHPJGZAk84RrIox6WKJ86GMu74qzu7QKX1AL2C2/3aBeH+HTb3ejxxktdcebxedHasH/QzOmBAC/u+YsnTL++6OD8e6nW/FB0Hed4SBsMc70ukJdvV/Jg+Mmrljw+fn5SE0NjDr3798fhYWF2LJli/DYsWPHYvny5ap/8+bNc0MMS/gKxH7aHyjVH+h0kJWPrdXCJl3Y9SeKIj1CMzPVCtHON81/+GazFvnusrZCa90j1Q5851r45y0ckIPIhbA5ovwpTmH3cnpPfdy9jNc/3IA/v/U9d+3AMV3bNQcAPHjTLw2jkCKBvUPts8zPy1RSNPCYGSCRTkTaVaHvvV5xfgedBd8yNxPjhvdA+6APPSPdiWKMTw0frSyzrij4ffv2Kb83bNiAPXv2oEOHDsJjc3JyUFxcrPpXUGA/zMmIPQeqUWMR9y3G5kCpyPq3PcgaOO724T10+1Z+H8jxzuKCDx2twV8/WGfrulpELhq78IqbJQFj8L523prSVmitoqs+oU7D6wT+2kbL8y3/Wr0kXL1Phs8n2541GinMx+20J3f4WC2e/sca5e+y/dV4W5OSl8W2s+fdv2cRfj2kK4b2ax+2vLde/Qv8WtNIMPedtgyffFumyr7JMDNA3Gpbb7qim+pvr1H0VfCGGSY9Yy0s+jSas0fDQTQvwA0sFfyTTz6Jiy66CBUVFbjllltw5ZWB1U/GjRuHtWsDC+w+99xzGDZsGK6++mpMnjwZ06dPR35+flQEFiHLMu7443JM+9tXFsfZ22Z0j3DPZW1IdpY+H8n01wOrNPEt+Hv//dnmhdVUVtXgt39Yhs0mubONMHNz8labx8BPDOgVfiTxwrxSN1LwWnw+P+p9fuQ0SbM+2AWYXOFYrl+sLVd6WsJJWEoCMfX2SFwMHYtzlR4Bg62bqlXORs/czEXjltLUumSMfPDNssN5zw2/HoQdomXBWzZ9kydPxuTJk3Xb58yZo/wuLS11VyqHsIdjtM4nQ53MqB43Pr4Ed/zqLJMzQogqsd0ZaP8MDl6Z1U1thXrrY2e5PwBg1fd7sffgcdMJLkYcPFqDTTsr0UWjAAAgPdWrRCbwdU/rM9T6onWzYB3Iw+cJsbu6Tl3Qgk/xeNAmvwn2HHD2HPp2L8Ca9fYH/JmM4SqLmlM+pKZ4VWkZGEarNEUyOOj1SPAZmHTaxjrDoBcksuBlWcbcRevRp1vrsGXj0RbRSMHfN7o33vhoE7qcph/rs7p2nOn3+HbRxJo7Spc7PmfPgWocOVaLfyz8Sbj/y3XlOMyF+Ym6n44rtknl1Ia0sUbBFWwqhcfniKe1N22ShlbB7Hm8gunbvUBVqZlSqj5Zh5ra+oi67PwHr/XtG7lgfD4/fH4/PB4Jl/Ru6/ieTqeM19b5sOqHPbpViuzCGi5RT4ft0yr0SCx4r0cyVJbaxrimVmzBf/q/MlW9AIAjx2rxn0+2YvJs/cC/HeY/HfAKtMnPDm6x16i1aJaJu67r5WhwUllYJs5MeCdzPZyQ8ApelmXbWRP53NNsejpvkSgxwT4/nvr7Gjwwa1Von0Bbbd51GG98ZF8Rm9XNkzZWpbHKMOjkoz1yTB8eaDQompbiwcA+gVl/fGXzeCSMuDiUY5tZgb+evBgTnvnEUJ4h57WzlI9P5ar17RsV0+eX4fPLSPFKYeUcclrn6+r9KH3tG8z69w+O7wWEnpeocrN9kqaGRpJLyevxGCpDbdE37TpseJ1Pvt0t3C5aeMQOGekpOLNjC6XhdtMtpSWay+9FAp8Gw00SXsGbJcoygz1QXmn6NBEF5ZyrQ+SiefndtXhz6SZTxcrHoJtxXNBN1+K1iLAxmsUp4gMH06PTUr2Kj17XfeY2VFbVKJbn/soThs/FTiVTWfAOylXv88Pr9VgqhY6CBFVOfemRDozd/MRSVJ+sw9FqfeVWlKWmIJGEInq9kmFIYbjXFb3jXwpcNU0F4088qV6P0ovVfh9uui/SoxCK6AZVxyPPlCki4RW80aQRIFDZX37nR9WkHgbrFvP+XRZ9IlIoZt+/2T6++26kdD5Y+bOtkEIrw4gt+AAA5/5CH5kUbrc0OzPNUHjeWnv9ww2Y8fb3yt/suTz9u/6qc+wYUXylZu+oLZuyblKOr9fvw7Y9Ry0bkTYts3Xb+F6adik3EZHGfQPApBmfYdNO/RKORoOskYSBeiTJ0Lfu7NsICfXqB+tUM60B/YS+O0f2xBXni6PqFNk8kmGZ3YwwmXRTH4y8tJMSYhkvnN05OnMdEl7BG8VIA8APWw5g4ert+Mt/ftTtY9YCPxDHZl6KlzMzrgBmubLzc0N5O4yUzpz31mHOe9ahkVYuGt7twrue2FnhKocmmSlKpZM0Mmi742u4NUNlWcYV57fXTZixM1DIK3j2PiZc2xOAvZ6K1R2Y0hhXciYnb2i/2ZwFrVxOeGnSQEwaE0r/sXtftbA8bNxB+82YZf4svfMCdGuvHyRneDySbrJdbnY6AGC/TTdn4Dqh3x98pu8JZgZ7CZ1Py8X8P1yJIee1R3GwcdbmWWJIkhRyS2n2mdVxp7TKy8JNV3SPO1dNno3vLRwSX8GbtO6swtb5/DrlJpruP/HZT3HVve8LQ8TMKvP1jyzGxp2VuPmJj/D9ZvWMQDe/IyPf5kW92uiWEOPdDfsqT2Br2ZEIFHyqUul0IWyav/kK7Pdr9mvSgJiFufGNFYvOaZWXFbyuDQVv8dxZD45fEJ1/ZnYmz4QTHtm2dVN4uBnATbNSsVUQ1mrkouHf4aQxfXDNJWcof3fv0AJd2hlHlHi9km6Aull2mmV6DD3mD5c1Is2yQ/mNBpzdBjPvvwRvTLscIy/tBABo2zobD98cWB3MI0mh56m5fLxZ24lEwit4M/8cqxyyX7YdagcAxwQDHlaVec1PFTh0tAZ/W6COynFzZqXZ+ppa61577Mz535taf2ZkpqcolU57H22jw6e5lWVZZ/EDgS78hGt74vm7L8Z5Z4onub3y3lrlN1ugOSPdi3YFTXHLsO6WMq/frnd7qGQIKqGcJumcvKH92ZnWa6iG66Lhn+GxE2LXHGvUtM+Xv2frFlk6n7LZd+6RJKSnepVVi4DA4Crvwixs2UR3np1nwcMmHvGySpKEdgU5ihwA0KltHvr1KAzu5waWIeGcLq0w7IIOikwfPHO1IxmIAAmv4LXhhTu5QU0l5lV2NrsznAlRuU0DikI3fd9FBW+2vqZ2gQitvE0yUsNWSKkpXiXDpDb/jFbh8zlfZFk2tKSH9muP/LxMewmxuFmdM+8fiF9d0snynBqLJeYmXNsTt159Jrp1CLk0+Ea8icEi2bxLx2GOMQU76ShYo2bkg7/8/PbofFqeLnUAG3tRrUjEIUkSZt53ieF9Re6z345Qz8C2+o4yg70fo3cr6onyPniPBEy9vR9+OyJUhnhzqSQKCa/gtRb8nc98gs9/DKxCxL6J77ccwJLgItJ2EClSu4NQWkvfjYE4hjZiiFUUv19WKd62rbNx7UC1EszKSNGVK0uQ3VJkAQbCDgO/tQ2JWcXzy+5k7Qsn/M4q7KxZdjqGD+ioaqD4NWZFs44BoF+PIky/80IAwOofrZfVE2GnHH4DF02vzoEZ4mzQUrs6VK/OrbDg2RJ0Fkz+MRrENJPttSlDdO/cKnsmC8V0kh2St+DjNiNYApLwCl6U8/oPc78GoLYgRJnqjBBF5lhZa2yQNLoWvFqI0UO6KvfgFdXDN/dFXk666tgUrwcPvbRata2ghb47/pGgIeQtTq0Fb6arAha8ewreyaXGXN7N+iColU0u98yaGLglvF5JUaosjxBD1GCKsLOyF3PRaMt8Wd/T8M+pQxW/tFFvQDQg3yw4oMqXWZahyvIpcsFlZarL9driDaoQYv29AzIZuTVZo6XO+c8Nspo8notsRDcRIRJfwZu4XsJVrnyvgP22O6CmbQiMFoEOB60ITKH4NQre45F0Fd/r8egH0wRF+mbjft02LzdxyMoHz1NzyoejXL510UIirExtWzfFry4+Q7cfCDVsVlFEPH1trtPJW6fn9yhSfhvFi3uk0GxQba9uyHntld/9zyqCEeye2gVTeFiZ9TNZJUVRA8bru2rPe/9PVyu+dFXCOL+Mvy8MGT/a9+nxSDi9SD9n4N1Pt+q2he5tuEt1D5mrGvwgq9Hp75RehXtH9za/eILxwj0D8PJDl0bt+omv4E0SURmtKG8Fr+BfCs5StOui8WkzLAYtsb9OviwsWczgFbwqT7vHI1DE+vNFU/Pzmqbrtnk9HqXSaRsOK3eD1eLLTIabr+yujGNoMYooCZeXJg1UfvPy9+tRiFn3X4I/jO+PM4pzuanzanmZGFr7gcWYZ2em4sGxv8RZgnzqQKgXJHkkXHF+e+ExRrlotPTrIW5IRIpa9Fub6Ex7ntcjIS8nA//+4zDVdrO0wVbfhBL8oFm1y29R5tQUj+NZsvFOx+JcFAnmZLhFwiv4OhdjZJVrcn7obzYGUiHbt+DFLhon1qcI0cSlzPRU5R719aH78lYmQ7SMmdlC1DweT8gHr1McFgpINHNQ+ChNLiOKKDFrMJ+ZeKGpTG25NT61r+W0ghyc2bElPB4Jt3EDqgAwemhX5Ganq8Y+eJjVz6xv5i/XkhJsbWUZaNNKXLmZkWHVpuU0ScPj487DAzepl9Y0+97M3pk2NS87Vvse2SIs2rj7p8f3VxS00W1YA8cbQx7JeKITET4Jr+CjkUeZt+CPBHN32121xyiFbqSWh2iCSFZ6SKGc5KJGPB69pf3VT/ayJIqijQKLUwfkd2rB84pBVHFFyj4txaOaEMR83bxl1yovC0//rr+SBI3RLDtNmBHTCDMLWbtr1GVdIEmS0IcMhGLn64KNrZFNkJYa9FH79dFPDDYXw06vpXfX1rigp9o3bfZenAyyGl2HpdY4pEk81iPYOJphZcHH66IciUgSKPjwLXijtRu1Su6LteW24+h1i2D4mAUf/qPu1SlfWClTOUXBL2sXycAmazD5pFQnuIVUtJahVc/Eq0rmZnwcf5XLz+8QsLItitHjjJa4e9Q5qm38TM2XH7oUt179C5VLxglGi497DS34wDNj34qRW49Z+vU+v+75ndkx8E2y9xnuuzRTsmaNhshFI4It5lIpmDCo5C0yeH6hMYzQNon3wZN+d42EV/B1Bj54OwOsRh+SaPKUXQtee8lIXTRD+7XHY7edp9o25vKuGFdyZshVIMuqCBtZlpGVkWI6bZ0dp+XLdQFLf8Z9FyuzHk/W1hsOdDrxi7PBQX6QkCFJku592Lk236M4vagZ7rqul/J3UctsDB9whq24c2FqAu72f/6/i0NyGbxL7cCs0SfIzyZl1+pY3AxvP30lnrj9fACh9Bfh2gVm31t6mlc1A9bsPKOy/rDlIA4dPSk0fCwteEED6ZEkReGTfnePhFfwuU3T0Sw7TedLNUtCxjCyMETnWsX+KtfUXJJF0YTjohlXcibuGNFDFynRqTgPV1/UUYmKKGyRraosGWkpkCQJ0+8y90WLFC2jsEUTPH/3AADA+WcVheKyHUTRAOoezWV9T8M9vz4HV114urJNuFIW7Nd0Pmzzz/dejLPO0Pu9jSJNGKV3XoAX7hmg286K1r1Dc5zephm33Z6CN+qy8AqeKVRJCuSJYXMOag0yK9olNSV0j4vOVrtvJEnCzcN+ITxPFLVjxN3P/Vf19yW9i9XnGJwactHw97F3T8IZCa/gL+zVBnMfG6KzluwkKDK04AVWSbhpiSOx4E9v00xxcfAfPbtWcaummHLbeZgwsqeigB+4qY9hDLeWa0xmhEqShLatm2LBsyU4ozg3bAXPB+p4PBIG9mmrehbqpyqZ/CWGWedmclhZ8N07tBAme7JyMWjR5nkxtOBT9QqejyBJS/VyLhpT0Q1hfn4AuH9MH+ExolxAHhsx+owj1eoUt2d3CWREtOp5sdfBN/78MyX97h4Jr+AlSYLX68H1l3VWbR/92Ic2zhVvFw002k91oL7oa4s3AAhV5DemXW7zOsahaHwl7NOtNTLTU5TKwmevBALLmokY2KctzunqPEWpVulZWVt2w0tVl1EmNNpx0QSOMWtnrCx4Y6HEchgpeO0kML7sudnpmPPwINX1LuzVJjQpiGsN0lI8jgZZRaSlWCdL491ODDv3M/puQrNvzc/nXYsM/hmTgnePhFfwjDFDu6F/T+PJJSKMLLR9lSd027aXH7V1Tf7jlgUWilG6VBGqlL/cdUWV0BNUFKmaij3gnGLb9wsHBwa86QES9D54OxU9RdDD0RKugje6pJESlAAUtMjCLUH3B6/AOp2Wq5o5PP8PV+Le0b2Fk6ZSU7yK+yLcsRs7LsEWzULGwLjhgZBQOwo+1aBHpO3lGV2JTwLIUN+WNLxb2JtbnSA4zvti8B0t/nyHbttfPxCv3arl4NEarPv5IM7s2FKXTc8phtPQBd1opsTCtlYtMHqyVorEyoKXTUbW7DwxkQtLS9gK3kACo1tJkoQ5D4fi81U+Zs21mL9eZM3yj9RsQpGbsJ6fnc/ULOld4BrmFxHt95AFHxWSxoIH7Cn4wee2U367NTNSy0MvrcbeA9V4/cMNEV2Hr+giHzxPSnCbnYgRIDSV/+YrrVPvAiFlpX1k1uvEml+X+a21E2wA9eIiRr0zOy4aSZIw+8HAdHBHFrHBoUbX0H5P2jhv4bW8+ogSvtzaHlm06NGxJfLzMjHqsi6Wx2ojZ7TGhTLGatTTETXmNMgaFZLKghdZFtdf1hlvfbxZ+fuWYd3Rv2cR0lO9eHv5Zt3xPEUtm2CvSVIlMx6f86WyQpQdLu5djE+/LVNtM/rQRTH1zNKz4/N+adJAZTbnNQM7YWvZEaz6wTwzIots0UoUaSM54dpeOK1gG3qc0RI7gmkNRNNdugiyIwL2XDQA0CY/G/+cOtR2A2iGYa9FG0HFvQqj1xIaZNVfxuORIp4BbcUrDw3C/soTyM5Kw98mD1btK73zAuE5WgUfmAAGDDg74A60+gTZu+IPU1nwNmUnrEkqBS9SNmOGdsP6bZVY+/NBAAGFcE5wtF9abn497dqSTrCzxioAPHbruejZKR9er0eg4Lnf3HZRpR8ztBuemfet5VJz7QtzUNAiS7WtQ1EzSwUvFAp2XDTml8ttmo4bg5kftVfilbZhUi2PtQXPMAsLdYJRo2ZmwRvNuA4pO707L1J324v3XhxYT9eEwpZNhIt8AIHoIhHaOSFpqR4MHyCIqzd0ZYm2kYsmGiSVgjdaUJjFsPfvWaSsNgPorb4z2uaqlk+LxNo7dsI8HzmjaVaaatYoj2Sg4UVKdcA5xbYGVGcIFnu4ZmAnZGWk4OV31wrOCGKgqK0s53CWtQtdO/TbKBEZG/Dr1SU6ixaLMH5f6r/5ovMzjVXnmFzHaDDTLh0EWSDtMP7ansJJco/eei7yczPxIrewOuB84RPR2Ib6UycN7xZJpeC1ccgM5t+8vF971fZzurTCNxv2KX/naiw8kQWV4vU4Wv7PCjP9aLRLNMgaCV6PZJj5kKG4TRqw7vEVvWWzTOExGekp+MsDA5X1Wl3FoG0y6rWYWfCidX75c/jGgKVYttsLdBttPWGwcRv90o/OGnHlMfFzJHgLPqlGBmOL5aMsLS3FwIED0aVLF2zeLPZZ+3w+TJ06FYMGDcJll12G+fPnuy6oHUYY5hMPfElai3zYBR3QJj/UPdUqL5EFNXpo1wilVGNqARu6aJzVgFn3X4LMdK+h5QlYV1GmrJzqd7tx8MJ7cTfjc8xoKW7V1LRskRJuo8b3XgzTWguufbLW/QR6bqKd9Oc4eM1qkJUseNew1BSXXnop5s2bhzZtjFdSWbBgAXbt2oWlS5firbfewowZM1BWVmZ4fLRo27op/sRNz7/16kBsL6to2pV0JElCbtOQz1r7YWlD1NJSAzk8Xn4wlKC/T7fWEclsmtlP5ZeUhNvtcFpBDt5+ehj+o8nprcJuJTW49bD+HcSXdVL5NddWxf7HMA+43TJo3VH8n5NuFM8mVSz4sCSLDdoerFEjbvzGBGGSHgNrhogISwXfp08fFBYWmh6zePFijBw5Eh6PB82bN8egQYOwZMkS14R0Apum36EoB8MHdAQQctFY+dStkl1JEoJJsULbp2gSgTkhPy8TbVs1tT5Qg9suGkA7q9D4OJF1teDZEvz2V2fpUvcC4Vnw/OQnRrwt9NA8Rz8moC3qNZd0QvcOzfHGtMuN/eHxVSxbDD2vnepvbbmt3jl7laKBZSAhH0nc4oq3q7y8HEVFoTjlwsJCVFSI849XVVWhrKxM9c/o2HBok5+Nqy88XZV/gyl4r4mCL2zRBHf8Sr0SvVapsL/c8kP/bfJg1aCvFqOPPtqhc6KG0I6efub3F+m2OYlc0aVB4MSI1pwFO4huPXfKUN027TyM/LxMlN55oensZaVcggd8Wd/TnAnaQPzqkk7o2i4UtipaGQwwi4O3GGQlDe8aDT7IOnfuXMycOTNq1/d4JIwb3kO1zU6e6buu74WWmjwuRlPnozUR45yurfA/bk1U1V24P6Kh4JtkhBKUiRW89TPMa6oP0bx71NmOZQnFwcevBS8ikoghEZG6/6KJduFuHqunIGrTjNyRRGS4YsEXFhZi795QHHV5eTkKCsSLHo8dOxbLly9X/Zs3b54bYhgSSoLk7MPRf2hScLt669Tb+zm6rlHEyiM398VrU4Zob6eTJRrKrlXzLIy/JtCDcWMyECPbQe4dg8cNIDYWvJFlanh8GArezAcfz3qO/x6dFlukwFUzecOWitDiigU/dOhQzJ8/H4MHD8aRI0ewbNkyQ6Wdk5ODnJwcN25rGxan69TyFfngAb0r4RyHMdhP/PZ8oTJIS1VHuhgpNTNXUyR0DcY+i8JDQ6kKGq76eVSNWoPdVofdqA6n8eCAxXhHHGt41bfp1IQXUOPSimSEGstq8+STT+Kiiy5CRUUFbrnlFlx55ZUAgHHjxmHt2sDEmJKSEhQXF2Pw4MG47rrrMGHCBLRt2za6kjuALe5rx/I1y0stKcdEJo/XI9myko1mskbLmmXXFSW4EqUPaEhi6YO3suRZnpxwZp6auODj2pLl64BWdPZtZxmML4nepeoZx3PBEwxLC37y5MmYPHmybvucOXOU316vF1OnTnVXMhdhCyzYiR+f98Tl+PXkxQAEH2IsLYvgrdPTvLpwT9duEbxsapSubxeRvz+effB3jeyFPl1b44y2uY7PNV/0O37LzMumHXvo1TkfYy7viivPF4fOihQ4vxpW/JY68WgUc8Yeu/Vc3HRFN7TM1Q8Cat022dxqSIYWfANVPFEFb5GTEbWKbzQhDLA3yAoEEpnd82vnA6uAeSKzWCp4KxdNk8xUDIo04iXBTHj+3fQ7Ux1G7fFIuH5QF8PxFyVMkityr86hpRbjuWFLNBqFgi9o0QQjL+0s/HB+f/3ZuOL89uguyL1h+KEJNl/c2zgPzGuPDzHcZ4Zodl/zZubJxCKBTWAxz0FuXvnatm6KgX1cCu+L9SBrA8w+MitXLN1SVjDRJt3YBx2Lc52dK/iGenRsqfRM47jYCUejUPBmtGqehd9d01M4cGm0ALGo4t17Q29hgiZAHD5oB74isFtaZYuMhPr6gEaLNMmVW6jGHWJpwUfz1gmqzJS6EM57MTiFzZmgVAXuER81OU7RTXSy+O74/eGsd2p2PUY0FXzn03Ix5Lx2uFewjqvRgh/RIJTYLD5cNNG05BM1TNJjYuxYoQwsa0qtRJDFcbkTjaTKJukWXo8En192PNEpknwxVjAlk8VNSHIbr9eDO0f2Mj0mutascYMaz+6KSHCaFiJeCNWFMM41KFcaWxEqXKEIHaTgBfz5/y7Gtxv36VZz8jpYXMINeKuVZSNMj2LWRDOcTvpxg3iZyRrNtkVZ8EM0xhrHmo5Z2+GlGhKfxMJMk7UxjwWk4AW0K8xBu8IcvPjWd6rtHhZmaWjBh35f0LMIF/Yqwoma+rDl4O/C8okb5byPOkqdtFf5pt95IbKzwuxtCNxBcRwlGRFmxYpnPXfzsO5IT/WiR0fxqk920DYOyvqzcVzuRIMUvAk3DOmKw8dqMfjcdnj6H2ssLXhmeUy57Tx38ohwNZytCGS0alW0cbrgR7cO4gFnM/QuMUn4u8FogE5LqFj6m8Wzi6ZVXhZ+H0aeIcC4XFnBJTKNFkchnEODrCa0zM3ElNvOQ1FwzUorN8G1AzsBALpwmfYiIZ4s+HAX/AjrXsH/49mCdQu7C740BnKaBOLmjx23t9wlYQ1Z8HYIVrSQBS+ueWd3aYUFz5a4d1vuNswHH82Vi2wRTX+09u9GoOHNUhUkrS/aIkzyeE1slipMRkjB20DJJ88s+Aaqd7yCU2aZxirrVgyWHIq1essMugy0aaTdhCz4EKMu64LaUz4M7tvO+mDCFqTgbRBS8A07ys/fRVYSpjXIrXWIcrRHnRgruM6n5WHSmD74Zffo5WUPxYQL9kXtrvFJk8xUjL+2Z6zFSCpIwduAWc+ehp5Kzd0nFul6eezmonHzXvHgorjwbOO1iN3ArMFMVhdVcpYqPqFBVhsoFrxS4RrmE+UVnN9ByuNo0CDpgpNUoZlhng++4eSIBWGt10s4ghS8Ddq0ygYAjLjkDAANF5OtXlMhTqzaBrx/rIvaEEgmPpp4DpMknNOhKAeZJmswRwNy0digaVaaOjomBj4aZuzETMHHwNiKeWPWACTqRKdISFbXkxUv3ntJg9+TLPgwiKkFH6M3dtWFpyM3Ox39ehRaH+wWjUAPKKkKxCZ8UkMemuhDFnwYNJQFwt/FH+NB1ratm+L1qUOjeg9dHHyyaziYW+mNoQdDRBey4OMY9cr1sR1kbUgaMjVxrDGb6EQQkUIKPo4RLVyfzFadWS6aZCVRs0kSiQEp+DhGtLBxMlvw/XoUoX1hDq4JRislb0lDiJKNKbnWk/QJUMPVcJAPPgJOb9Oswe7VGNwWOU3SMOO+UKRBaInEWElkzpyHB0WcG8h8olNEl457KA4++pCCD5MX770Y+XlZDXa/uImDb0CsVtCKNQUtmkR8DTMffLyWO1KStWcSj5CCD5MORQ1nvQMNmyogXoh3Be8GZmVL4mITDQT54BOEWIdJxoJ4d9G4gVmysWSnMZa5oSEFnyg0Ah+8FiXzTxJreLOSJas7LkmLFZeQgk8Q/I3QB8+0XxLrd3Maa7kJ17Dlg9++fTsefPBBHDlyBLm5uSgtLUX79u1Vx8yYMQNvvPEGWrVqBQA455xzMGXKFNcFbqyEfPCNp9azxqxRlJkbZZUQ6LAlfanJRxN1bCn4KVOm4IYbbkBJSQnef/99PPbYY3jttdd0xw0fPhwPPPCA60ISvA8+tnLEgqRW8KaDrEla7iQtVjxi6aI5dOgQ1q9fj2HDhgEAhg0bhvXr16OysjKsG1ZVVaGsrEz1r6KiIqxrNSYaY5gkozG4aHhjNmkVexD2Daemkoc42lha8OXl5WjdujW83sCEDq/Xi1atWqG8vBzNmzdXHbto0SKsWrUK+fn5uOuuu3D22Wfrrjd37lzMnDnTJfEbD40xTDLWq1g1BKKSeT0SfH45aWctd2qbi+sv64zL+7WPtShJj2tx8KNGjcIdd9yB1NRUrF69GuPHj8fixYuRl5enOm7s2LEYMWKEaltFRQVGjx7tlihJSWMMk2wMvZaM9BS0bZ2N0UO7Kdu8XgmoT15PhiRJGMOVl4gelgq+sLAQ+/btg8/ng9frhc/nw/79+1FYqM4Lnp+fr/zu378/CgsLsWXLFvTt21d1XE5ODnJyclwSv/HQGC14fyMos9cj4aVJl2q2eQD4klfDEw2GpROsRYsW6NatGxYuXAgAWLhwIbp166Zzz+zbt0/5vWHDBuzZswcdOnRwWdzGi98f+D+ZrVktOU3SkZ2ZinElPWItSoPiZYu7k4YnIsSWi+bxxx/Hgw8+iJdeegk5OTkoLS0FAIwbNw4TJ05Ejx498Nxzz+Gnn36Cx+NBamoqpk+frrLqicj4ZffWWPHNbqRHmNwqkUhN8eDNJ6+ItRgNjtfDwkNjLAiR8NhS8B07dsT8+fN12+fMmaP8ZkqfiA53juyFMUO7IaOBF+0lGh5PcF3GxjTeQkQHilOKQ1o312epTE3xID8vMwbSEA1NStBF4/fTTCAiMsgcjENeuGcAqo6firUYRIxgLhofG3ghiDAhBR+HZGelITsrLdZiEDGCuWh8ZMETEUIuGoKIM5gFTy4aIlJIwRNEnHHR2W0AALnZ6TGWhEh0yEVDEHHGtQM74cr+HZCVkRprUYgEhyx4gogzJEki5U64Ail4giCIJIUUPEEQRJJCCp4gCCJJIQVPEASRpJCCJwiCSFJIwRMEQSQpcREH7/P5AIDWZiUIgnAA05lMh2qJCwV/4MABAKBl+wiCIMLgwIEDaNeunW67JLO14GJITU0N1q1bh/z8fGVxb7uw9VznzZuHgoKCKEkYXagM8UGilyHR5QeoDE7x+Xw4cOAAzjzzTGRkZOj2x4UFn5GRgT59+kR0jYKCAhQXF7skUWygMsQHiV6GRJcfoDI4QWS5M2iQlSAIIkkhBU8QBJGkkIInCIJIUhJewefk5ODOO+9ETk5OrEUJGypDfJDoZUh0+QEqg9vERRQNQRAE4T4Jb8ETBEEQYkjBEwRBJCkJr+C3b9+O66+/HkOGDMH111+PHTt2xFokFYcPH8a4ceMwZMgQXHXVVbjzzjtRWVkJwFz2eC3XzJkz0aVLF2zevBlAYpWhtrYWU6ZMweDBg3HVVVfh0UcftZQznsrwySefYPjw4SgpKcFVV12FpUuXWsoYa/lLS0sxcOBA1TcTicyxKI+oDGb1Oq7KICc4N954o/zee+/JsizL7733nnzjjTfGWCI1hw8flr/88kvl7z/+8Y/yQw89JMuyuezxWK5169bJt956q3zxxRfLmzZtkmU5scowbdo0+amnnpL9fr8sy7J84MABWZYTowx+v1/u06eP8tw3bNgg9+rVS/b5fHEt/9dffy3v3btXvuSSSxTZreSKt/KIymBWr+OpDAmt4A8ePCj37t1brq+vl2VZluvr6+XevXvLhw4dirFkxixZskQeO3asqezxWK7a2lr5uuuuk3ft2qV86IlUhurqarl3795ydXW1anuilMHv98t9+/aVv/nmG1mWZXnNmjXy4MGDE0Z+XjmGK3Osy6NtpHhYvZbl+Pqm4iJVQbiUl5ejdevWSv4ar9eLVq1aoby8HM2bN4+xdHr8fj/efPNNDBw40FR2WZbjrlx//vOfcfXVV6Nt27bKtkQqw+7du5Gbm4uZM2fiq6++QpMmTfD73/8eGRkZCVEGSZLwwgsvYPz48cjKysLx48fx8ssvJ9Q7YIQrc7yWh6/XQHzVi4T3wScS06ZNQ1ZWFsaMGRNrURzx3XffYe3atbjhhhtiLUrY1NfXY/fu3ejevTveeecd3Hfffbjrrrtw4sSJWItmi/r6erz88st46aWX8Mknn+Avf/kL7rnnnoSRP5mJ53qd0BZ8YWEh9u3bB5/PB6/XC5/Ph/3796OwsDDWoukoLS3Fzp07MXv2bHg8HlPZZVmOq3J9/fXX2LZtGy699FIAgWx5t956Kx566KGEKUNRURFSUlIwbNgwAEDPnj2Rl5eHjIyMhCjDhg0bsH//fvTu3RsA0Lt3b2RmZiI9PT0h5OcJ99uPx/Jo63Uk5YsGCW3Bt2jRAt26dcPChQsBAAsXLkS3bt3izj3z/PPPY926dZg1axbS0tIAmMseb+W6/fbbsWrVKqxYsQIrVqxAQUEB/vrXv+KKK65ImDI0b94c5557LlavXg0gEMlw6NAhtG/fPiHKUFBQgIqKCmzbtg0A8PPPP+PgwYNo165dQsjPE+63H2/lEdVrIL7qdsLPZP3555/x4IMPoqqqCjk5OSgtLcXpp58ea7EUtmzZgmHDhqF9+/ZKvubi4mLMmjXLVPZ4LtfAgQMxe/ZsdO7cOaHKsHv3bjz88MM4cuQIUlJScPfdd2PAgAEJU4YPPvgAc+bMgSRJAICJEydi0KBBcS3/k08+iaVLl+LgwYPIy8tDbm4uFi1aFLbMsSiPqAwvvPCCYb2OpzIkvIInCIIgxCS0i4YgCIIwhhQ8QRBEkkIKniAIIkkhBU8QBJGkkIInCIJIUkjBEwRBJCmk4AmCIJIUUvAEQRBJyv8Dm4zGu0WAaQEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# take a look at volume column\n",
    "plt.plot(Smarket.iloc[:, 6])\n",
    "# or plt.plot(Smarket[['Volume']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7.2 Logistic Regression\n",
    "There are some known complications that in Sklearn about applying parameter regularization. This can be aviod to set the tuning parameter 'C' to a large number. Here to be consistent with R output, I decieded to use Statsmodels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Direction[Down]  Direction[Up]\n",
      "0                 0.0            1.0\n",
      "1                 0.0            1.0\n",
      "2                 1.0            0.0\n",
      "3                 0.0            1.0\n",
      "4                 0.0            1.0\n",
      "...               ...            ...\n",
      "1245              0.0            1.0\n",
      "1246              1.0            0.0\n",
      "1247              0.0            1.0\n",
      "1248              1.0            0.0\n",
      "1249              1.0            0.0\n",
      "\n",
      "[1250 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "y, X = dmatrices('Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume', Smarket, return_type = 'dataframe')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.691034\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:          Direction[Up]   No. Observations:                 1250\n",
      "Model:                          Logit   Df Residuals:                     1243\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Wed, 14 Sep 2022   Pseudo R-squ.:                0.002074\n",
      "Time:                        11:15:03   Log-Likelihood:                -863.79\n",
      "converged:                       True   LL-Null:                       -865.59\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.7319\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.1260      0.241     -0.523      0.601      -0.598       0.346\n",
      "Lag1          -0.0731      0.050     -1.457      0.145      -0.171       0.025\n",
      "Lag2          -0.0423      0.050     -0.845      0.398      -0.140       0.056\n",
      "Lag3           0.0111      0.050      0.222      0.824      -0.087       0.109\n",
      "Lag4           0.0094      0.050      0.187      0.851      -0.089       0.107\n",
      "Lag5           0.0103      0.050      0.208      0.835      -0.087       0.107\n",
      "Volume         0.1354      0.158      0.855      0.392      -0.175       0.446\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# since we are more interested in stock marketing up, we take the second column of y as our response variable \n",
    "# we build a model to predict whether the direction will be up. \n",
    "logit = sm.Logit(y.iloc[:,1], X)\n",
    "print(logit.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.691034\n",
      "         Iterations 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Intercept   -0.126000\n",
       "Lag1        -0.073074\n",
       "Lag2        -0.042301\n",
       "Lag3         0.011085\n",
       "Lag4         0.009359\n",
       "Lag5         0.010313\n",
       "Volume       0.135441\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to extract the parameters directly\n",
    "logit.fit().params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.691034\n",
      "         Iterations 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.50708413, 0.48146788, 0.48113883, 0.51522236, 0.51078116,\n",
       "       0.50695646, 0.49265087, 0.50922916, 0.51761353, 0.48883778])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to extract the probability of the market going up for the first 10 instances\n",
    "logit.fit().predict()[0:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.691034\n",
      "         Iterations 4\n"
     ]
    }
   ],
   "source": [
    "# in order to make a prediction as to whether the market will go up or down on a particular day, \n",
    "# we must convert these predicted probabilities into class labels, Up (1) or Down (0).\n",
    "# we will do this by threshold the probability by a predefined threshold \n",
    "threshold = 0.5 \n",
    "predict_label = pd.DataFrame(np.zeros(shape=(1250,1)), columns = ['label'])\n",
    "predict_label.iloc[logit.fit().predict()>threshold] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[145, 457],\n",
       "       [141, 507]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can evalue the TRAINING result by constructing a confusion matrix \n",
    "confusion_matrix(y.iloc[:,1], predict_label.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5216\n",
      "0.5216\n"
     ]
    }
   ],
   "source": [
    "# the diagonal elements of the confusion matrix indicate correct predictions, while the off-diagonals represent incorrect predictions. \n",
    "# in this case, logistic regression correctly predicted the movement of the market 52.2% of the time.\n",
    "print(np.mean(y.iloc[:,1] == predict_label.iloc[:,0]))\n",
    "# or use the confusion matrix to compute the accuracy \n",
    "print(confusion_matrix(y.iloc[:,1], predict_label.iloc[:,0]).diagonal().sum()* 1.0 /confusion_matrix(y.iloc[:,1], predict_label.iloc[:,0]).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# in order to better assess the accuracy of the logistic regression model in this setting, \n",
    "# we can fit the model using part of the data, and then examine how well it predicts the hold out data. \n",
    "# this will yield a more realistic error rate, in the sense that in practice we will be interested in our \n",
    "# model’s performance not on the data that we used to fit the model, but rather on days in the future for which the market’s movements are unknown.\n",
    "Smarket_2005 = Smarket.query('Year >= 2005')\n",
    "Smarket_train = Smarket.query('Year < 2005')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we will use the training dataset to build the logistic regression model \n",
    "y_train, X_train = dmatrices('Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume', Smarket_train, return_type = 'dataframe')\n",
    "y_test, X_test = dmatrices('Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume', Smarket_2005, return_type = 'dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.691936\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:          Direction[Up]   No. Observations:                  998\n",
      "Model:                          Logit   Df Residuals:                      991\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Wed, 14 Sep 2022   Pseudo R-squ.:                0.001562\n",
      "Time:                        11:14:30   Log-Likelihood:                -690.55\n",
      "converged:                       True   LL-Null:                       -691.63\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.9044\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.1912      0.334      0.573      0.567      -0.463       0.845\n",
      "Lag1          -0.0542      0.052     -1.046      0.295      -0.156       0.047\n",
      "Lag2          -0.0458      0.052     -0.884      0.377      -0.147       0.056\n",
      "Lag3           0.0072      0.052      0.139      0.889      -0.094       0.108\n",
      "Lag4           0.0064      0.052      0.125      0.901      -0.095       0.108\n",
      "Lag5          -0.0042      0.051     -0.083      0.934      -0.104       0.096\n",
      "Volume        -0.1163      0.240     -0.485      0.628      -0.586       0.353\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "logit = sm.Logit(y_train.iloc[:,1], X_train)\n",
    "print(logit.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.691936\n",
      "         Iterations 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[77, 34],\n",
       "       [97, 44]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = logit.fit().predict(X_test)\n",
    "predict_label = pd.DataFrame(np.zeros(shape=(X_test.shape[0],1)), columns = ['label'])\n",
    "threshold = 0.5\n",
    "mark = (preds > threshold).reset_index(drop=True)\n",
    "predict_label.loc[mark] = 1\n",
    "confusion_matrix(y_test.iloc[:,1], predict_label.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4801587301587302"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get accuracy\n",
    "np.mean(y_test.iloc[:,1].reset_index(drop=True)==predict_label.iloc[:,0].reset_index(drop=True)) \n",
    "\n",
    "# note: we have trained and tested our model on two completely separate data sets: \n",
    "# training was performed using only the dates before 2005, and testing was performed \n",
    "# using only the dates in 2005. Finally, we compute the predictions for 2005 and compare \n",
    "# them to the actual movements of the market over that time period. The results are rather \n",
    "# disappointing: the test error rate is 1 - 48% = 52 %, which is worse than random guessing \n",
    "# for a balanced data. Of course this result is not all that surprising, given that one \n",
    "# would not generally expect to be able to use previous days’ returns to predict future market performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.692085\n",
      "         Iterations 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.44047619047619047"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the retrain of the model with Lag1 and Lag2 will be similar to previous steps (I will be brief here). \n",
    "y_train, X_train = dmatrices('Direction~Lag1+Lag2', Smarket_train, return_type = 'dataframe')\n",
    "y_test, X_test = dmatrices('Direction~Lag1+Lag2', Smarket_2005, return_type = 'dataframe')\n",
    "logit = sm.Logit(y_train.iloc[:,1], X_train)\n",
    "preds = logit.fit().predict(X_test)\n",
    "predict_label = pd.DataFrame(np.zeros(shape=(X_test.shape[0],1)), columns = ['label'])\n",
    "threshold = 0.5\n",
    "confusion_matrix(y_test.iloc[:,1], predict_label.iloc[:,0])\n",
    "np.mean(y_test.iloc[:,1].reset_index(drop=True)==predict_label.iloc[:,0].reset_index(drop=True)) # to get accuracy on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.692085\n",
      "         Iterations 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5595238095238095"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another way to deal with logistics regression is to change the threshold value from 0.5 to others. \n",
    "# there is an example below with threshold 0.45. \n",
    "preds = logit.fit().predict(X_test)\n",
    "predict_label = pd.DataFrame(np.zeros(shape=(X_test.shape[0],1)), columns = ['label'])\n",
    "threshold = 0.45\n",
    "predict_label.loc[(preds > threshold).reset_index(drop=True)] = 1\n",
    "confusion_matrix(y_test.iloc[:,1], predict_label.iloc[:,0])\n",
    "\n",
    "# to get accuracy on validation set, we did see an improvment of the accuracy from 0.48 to 0.56\n",
    "np.mean(y_test.iloc[:,1].reset_index(drop=True)==predict_label.iloc[:,0].reset_index(drop=True)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7.3 Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we will use sklearn's implementation of LDA\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.iloc[:,1].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the training process \n",
    "sklearn_lda = LDA(n_components=1) #creating a LDA object\n",
    "lda = sklearn_lda.fit(X_train.iloc[:,1:3], y_train.iloc[:,1]) #learning the projection matrix\n",
    "X_lda = lda.transform(X_train.iloc[:,1:3]) #using the model to project X \n",
    "X_labels = lda.predict(X_train.iloc[:,1:3]) #gives you the predicted label for each sample\n",
    "X_prob = lda.predict_proba(X_train.iloc[:,1:3]) #the probability of each sample to belong to each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49017925 0.50982075]\n",
      " [0.4792185  0.5207815 ]\n",
      " [0.46681848 0.53318152]\n",
      " [0.47400107 0.52599893]\n",
      " [0.49278766 0.50721234]]\n"
     ]
    }
   ],
   "source": [
    "# testing step \n",
    "X_test_labels =lda.predict(X_test.iloc[:,1:3])\n",
    "X_test_prob = lda.predict_proba(X_test.iloc[:,1:3]) \n",
    "print(X_test_prob[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5595238095238095"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the accuracy of the test set using default threshold\n",
    "np.mean(y_test.iloc[:,1]==X_test_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5595238095238095"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's change the threshod a bit to see whether we can improve the accuracy. \n",
    "# the 2nd column of X_test_prob is the probability belongs to UP group. \n",
    "# the default value is 0.5, let us first check that. \n",
    "threshold = 0.5 \n",
    "np.mean(y_test.iloc[:,1]==(X_test_prob[:,1]>=threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5634920634920635"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.48\n",
    "np.mean(y_test.iloc[:,1]==(X_test_prob[:,1]>=threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7.4 Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# it is a little bit of annoying that QDA and LDA have minor difference in their parameter \n",
    "# set-up and function names. \n",
    "# from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5992063492063492\n"
     ]
    }
   ],
   "source": [
    "sklearn_qda = QDA(priors=None,store_covariance=True) #creating a QDA object\n",
    "qda = sklearn_qda.fit(X_train.iloc[:,1:3], y_train.iloc[:,1]) #learning the projection matrix\n",
    "X_labels = qda.predict(X_train.iloc[:,1:3]) #gives you the predicted label for each sample\n",
    "X_prob = qda.predict_proba(X_train.iloc[:,1:3]) #the probability of each sample to belong to each class\n",
    "\n",
    "X_test_labels=qda.predict(X_test.iloc[:,1:3])\n",
    "X_test_prob = qda.predict_proba(X_test.iloc[:,1:3]) \n",
    "\n",
    "print(np.mean(y_test.iloc[:,1]==X_test_labels) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_decision_function',\n",
       " '_estimator_type',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_more_tags',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_validate_data',\n",
       " 'classes_',\n",
       " 'covariance_',\n",
       " 'decision_function',\n",
       " 'feature_names_in_',\n",
       " 'fit',\n",
       " 'get_params',\n",
       " 'means_',\n",
       " 'n_features_in_',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'priors',\n",
       " 'priors_',\n",
       " 'reg_param',\n",
       " 'rotations_',\n",
       " 'scalings_',\n",
       " 'score',\n",
       " 'set_params',\n",
       " 'store_covariance',\n",
       " 'tol']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# again, use dir() to explore all the information stored in lda and qda.\n",
    "dir(qda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04279022  0.03389409]\n",
      " [-0.03954635 -0.03132544]]\n",
      "[array([[ 1.50662277, -0.03924806],\n",
      "       [-0.03924806,  1.53559498]]), array([[ 1.51700576, -0.02787349],\n",
      "       [-0.02787349,  1.49026815]])]\n"
     ]
    }
   ],
   "source": [
    "print(qda.means_)\n",
    "print(qda.covariance_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7.5 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB as NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5952380952380952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_check_X',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_estimator_type',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_joint_log_likelihood',\n",
       " '_more_tags',\n",
       " '_partial_fit',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_update_mean_variance',\n",
       " '_validate_data',\n",
       " 'class_count_',\n",
       " 'class_prior_',\n",
       " 'classes_',\n",
       " 'epsilon_',\n",
       " 'feature_names_in_',\n",
       " 'fit',\n",
       " 'get_params',\n",
       " 'n_features_in_',\n",
       " 'partial_fit',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'priors',\n",
       " 'score',\n",
       " 'set_params',\n",
       " 'sigma_',\n",
       " 'theta_',\n",
       " 'var_',\n",
       " 'var_smoothing']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_class = NB()\n",
    "NB_class.fit(X_train.iloc[:,1:3], y_train.iloc[:,1])\n",
    "X_test_labels=NB_class.predict(X_test.iloc[:,1:3])\n",
    "X_test_prob = NB_class.predict_proba(X_test.iloc[:,1:3]) \n",
    "print(np.mean(y_test.iloc[:,1]==X_test_labels))\n",
    "\n",
    "dir(NB_class) # use dir command to check what Naive Bayes classifier has"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7.6 K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier as KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5158730158730159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_check_algorithm_metric',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_estimator_type',\n",
       " '_fit',\n",
       " '_fit_X',\n",
       " '_fit_method',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_kneighbors_reduce_func',\n",
       " '_more_tags',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_tree',\n",
       " '_validate_data',\n",
       " '_y',\n",
       " 'algorithm',\n",
       " 'classes_',\n",
       " 'effective_metric_',\n",
       " 'effective_metric_params_',\n",
       " 'feature_names_in_',\n",
       " 'fit',\n",
       " 'get_params',\n",
       " 'kneighbors',\n",
       " 'kneighbors_graph',\n",
       " 'leaf_size',\n",
       " 'metric',\n",
       " 'metric_params',\n",
       " 'n_features_in_',\n",
       " 'n_jobs',\n",
       " 'n_neighbors',\n",
       " 'n_samples_fit_',\n",
       " 'outputs_2d_',\n",
       " 'p',\n",
       " 'predict',\n",
       " 'predict_proba',\n",
       " 'radius',\n",
       " 'score',\n",
       " 'set_params',\n",
       " 'weights']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNN(n_neighbors= 4) # use n_neighbors to change the # of tune the performance of KNN\n",
    "KNN_fit = neigh.fit(X_train.iloc[:,1:3], y_train.iloc[:,1]) #learning the projection matrix\n",
    "X_test_labels=KNN_fit.predict(X_test.iloc[:,1:3])\n",
    "X_test_prob = KNN_fit.predict_proba(X_test.iloc[:,1:3]) \n",
    "print(np.mean(y_test.iloc[:,1]==X_test_labels))\n",
    "\n",
    "dir(neigh) # use dir command to check what KNN offers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7.7 Possion Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bikeshare = pd.read_csv('https://raw.githubusercontent.com/tvanzyl/Sharing_ISL_python/master/data/Bikeshare.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   season mnth  day  hr  holiday  weekday  workingday weathersit  temp  \\\n",
      "0       1  Jan    1   0        0        6           0      clear  0.24   \n",
      "1       1  Jan    1   1        0        6           0      clear  0.22   \n",
      "2       1  Jan    1   2        0        6           0      clear  0.22   \n",
      "3       1  Jan    1   3        0        6           0      clear  0.24   \n",
      "4       1  Jan    1   4        0        6           0      clear  0.24   \n",
      "\n",
      "    atemp   hum  windspeed  casual  registered  bikers  \n",
      "0  0.2879  0.81        0.0       3          13      16  \n",
      "1  0.2727  0.80        0.0       8          32      40  \n",
      "2  0.2727  0.80        0.0       5          27      32  \n",
      "3  0.2879  0.75        0.0       3          10      13  \n",
      "4  0.2879  0.75        0.0       0           1       1  \n",
      "(8645, 15)\n"
     ]
    }
   ],
   "source": [
    "print(Bikeshare.head())\n",
    "print(Bikeshare.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first build a linear regression model\n",
    "lm_bikeshare = smf.ols('bikers ~ mnth + hr + workingday + temp + weathersit', data = Bikeshare).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>bikers</td>      <th>  R-squared:         </th> <td>   0.364</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.363</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   291.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 14 Sep 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:14:34</td>     <th>  Log-Likelihood:    </th> <td> -52635.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  8645</td>      <th>  AIC:               </th> <td>1.053e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  8627</td>      <th>  BIC:               </th> <td>1.054e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    17</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                   <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                     <td> -101.1052</td> <td>    7.269</td> <td>  -13.910</td> <td> 0.000</td> <td> -115.353</td> <td>  -86.857</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mnth[T.Aug]</th>                   <td>  -33.1123</td> <td>    6.410</td> <td>   -5.166</td> <td> 0.000</td> <td>  -45.677</td> <td>  -20.547</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mnth[T.Dec]</th>                   <td>   34.7242</td> <td>    5.908</td> <td>    5.878</td> <td> 0.000</td> <td>   23.144</td> <td>   46.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mnth[T.Feb]</th>                   <td>    5.3621</td> <td>    6.279</td> <td>    0.854</td> <td> 0.393</td> <td>   -6.946</td> <td>   17.670</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mnth[T.Jan]</th>                   <td>   15.8861</td> <td>    6.731</td> <td>    2.360</td> <td> 0.018</td> <td>    2.691</td> <td>   29.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mnth[T.July]</th>                  <td>  -52.1488</td> <td>    6.769</td> <td>   -7.704</td> <td> 0.000</td> <td>  -65.417</td> <td>  -38.881</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mnth[T.June]</th>                  <td>  -16.8499</td> <td>    6.343</td> <td>   -2.656</td> <td> 0.008</td> <td>  -29.284</td> <td>   -4.416</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mnth[T.March]</th>                 <td>    4.4564</td> <td>    5.906</td> <td>    0.755</td> <td> 0.451</td> <td>   -7.121</td> <td>   16.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mnth[T.May]</th>                   <td>   10.3534</td> <td>    5.757</td> <td>    1.798</td> <td> 0.072</td> <td>   -0.932</td> <td>   21.639</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mnth[T.Nov]</th>                   <td>   32.8573</td> <td>    5.705</td> <td>    5.759</td> <td> 0.000</td> <td>   21.674</td> <td>   44.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mnth[T.Oct]</th>                   <td>   34.6532</td> <td>    5.591</td> <td>    6.198</td> <td> 0.000</td> <td>   23.694</td> <td>   45.613</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mnth[T.Sept]</th>                  <td>   -3.0572</td> <td>    5.930</td> <td>   -0.516</td> <td> 0.606</td> <td>  -14.681</td> <td>    8.567</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weathersit[T.cloudy/misty]</th>    <td>  -10.5972</td> <td>    2.729</td> <td>   -3.884</td> <td> 0.000</td> <td>  -15.946</td> <td>   -5.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weathersit[T.heavy rain/snow]</th> <td>  -62.2356</td> <td>  106.855</td> <td>   -0.582</td> <td> 0.560</td> <td> -271.698</td> <td>  147.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weathersit[T.light rain/snow]</th> <td>  -58.2213</td> <td>    4.133</td> <td>  -14.088</td> <td> 0.000</td> <td>  -66.322</td> <td>  -50.120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hr</th>                            <td>    6.6441</td> <td>    0.174</td> <td>   38.286</td> <td> 0.000</td> <td>    6.304</td> <td>    6.984</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>workingday</th>                    <td>   -1.1738</td> <td>    2.489</td> <td>   -0.472</td> <td> 0.637</td> <td>   -6.053</td> <td>    3.705</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>temp</th>                          <td>  356.0133</td> <td>   13.007</td> <td>   27.370</td> <td> 0.000</td> <td>  330.516</td> <td>  381.511</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1288.401</td> <th>  Durbin-Watson:     </th> <td>   0.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2017.317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 1.044</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 4.113</td>  <th>  Cond. No.          </th> <td>1.26e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.26e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 bikers   R-squared:                       0.364\n",
       "Model:                            OLS   Adj. R-squared:                  0.363\n",
       "Method:                 Least Squares   F-statistic:                     291.1\n",
       "Date:                Wed, 14 Sep 2022   Prob (F-statistic):               0.00\n",
       "Time:                        11:14:34   Log-Likelihood:                -52635.\n",
       "No. Observations:                8645   AIC:                         1.053e+05\n",
       "Df Residuals:                    8627   BIC:                         1.054e+05\n",
       "Df Model:                          17                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================================\n",
       "                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------\n",
       "Intercept                      -101.1052      7.269    -13.910      0.000    -115.353     -86.857\n",
       "mnth[T.Aug]                     -33.1123      6.410     -5.166      0.000     -45.677     -20.547\n",
       "mnth[T.Dec]                      34.7242      5.908      5.878      0.000      23.144      46.305\n",
       "mnth[T.Feb]                       5.3621      6.279      0.854      0.393      -6.946      17.670\n",
       "mnth[T.Jan]                      15.8861      6.731      2.360      0.018       2.691      29.081\n",
       "mnth[T.July]                    -52.1488      6.769     -7.704      0.000     -65.417     -38.881\n",
       "mnth[T.June]                    -16.8499      6.343     -2.656      0.008     -29.284      -4.416\n",
       "mnth[T.March]                     4.4564      5.906      0.755      0.451      -7.121      16.034\n",
       "mnth[T.May]                      10.3534      5.757      1.798      0.072      -0.932      21.639\n",
       "mnth[T.Nov]                      32.8573      5.705      5.759      0.000      21.674      44.041\n",
       "mnth[T.Oct]                      34.6532      5.591      6.198      0.000      23.694      45.613\n",
       "mnth[T.Sept]                     -3.0572      5.930     -0.516      0.606     -14.681       8.567\n",
       "weathersit[T.cloudy/misty]      -10.5972      2.729     -3.884      0.000     -15.946      -5.249\n",
       "weathersit[T.heavy rain/snow]   -62.2356    106.855     -0.582      0.560    -271.698     147.227\n",
       "weathersit[T.light rain/snow]   -58.2213      4.133    -14.088      0.000     -66.322     -50.120\n",
       "hr                                6.6441      0.174     38.286      0.000       6.304       6.984\n",
       "workingday                       -1.1738      2.489     -0.472      0.637      -6.053       3.705\n",
       "temp                            356.0133     13.007     27.370      0.000     330.516     381.511\n",
       "==============================================================================\n",
       "Omnibus:                     1288.401   Durbin-Watson:                   0.571\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2017.317\n",
       "Skew:                           1.044   Prob(JB):                         0.00\n",
       "Kurtosis:                       4.113   Cond. No.                     1.26e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.26e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the summary of the model, we may see the coefficients are different from the R output.\n",
    "# the diff in the coefficients is due to the difference in the way we chose the baseline for the catergotical variables.\n",
    "# here Python used April as the baseline month - probably due to the alphabetical order of the name of the month.\n",
    "lm_bikeshare.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106.65534360848793"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after building the model, we could do other things (i.e. plots, other statistics, RMSE etc.) to further explore the results. \n",
    "# here let us get a sense of the RMSE\n",
    "np.sqrt(((lm_bikeshare.fittedvalues - Bikeshare.bikers)**2).sum()/len(Bikeshare.bikers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us go ahead and build a possion regression model \n",
    "# instead of use .ols(), we use .glm()\n",
    "glm_bikeshare = smf.glm('bikers ~ mnth + hr + workingday + temp + weathersit', data = Bikeshare, family=sma.families.Poisson()).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>bikers</td>      <th>  No. Observations:  </th>   <td>  8645</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>   <td>  8627</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>         <td>Poisson</td>     <th>  Df Model:          </th>   <td>    17</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>Log</td>       <th>  Scale:             </th>  <td>  1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td>-3.4404e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 14 Sep 2022</td> <th>  Deviance:          </th> <td>6.3504e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>11:14:35</td>     <th>  Pearson chi2:      </th>  <td>6.83e+05</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>5</td>        <th>  Pseudo R-squ. (CS):</th>   <td> 1.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                   <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                     <td>    3.0118</td> <td>    0.006</td> <td>  476.777</td> <td> 0.000</td> <td>    2.999</td> <td>    3.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mnth[T.Aug]</th>                   <td>   -0.2288</td> <td>    0.005</td> <td>  -48.719</td> <td> 0.000</td> <td>   -0.238</td> <td>   -0.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mnth[T.Dec]</th>                   <td>    0.2981</td> <td>    0.005</td> <td>   59.511</td> <td> 0.000</td> <td>    0.288</td> <td>    0.308</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mnth[T.Feb]</th>                   <td>   -0.1015</td> <td>    0.006</td> <td>  -17.160</td> <td> 0.000</td> <td>   -0.113</td> <td>   -0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mnth[T.Jan]</th>                   <td>   -0.1450</td> <td>    0.007</td> <td>  -21.388</td> <td> 0.000</td> <td>   -0.158</td> <td>   -0.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mnth[T.July]</th>                  <td>   -0.3777</td> <td>    0.005</td> <td>  -76.183</td> <td> 0.000</td> <td>   -0.387</td> <td>   -0.368</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mnth[T.June]</th>                  <td>   -0.1502</td> <td>    0.005</td> <td>  -32.493</td> <td> 0.000</td> <td>   -0.159</td> <td>   -0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mnth[T.March]</th>                 <td>   -0.0312</td> <td>    0.005</td> <td>   -5.833</td> <td> 0.000</td> <td>   -0.042</td> <td>   -0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mnth[T.May]</th>                   <td>    0.0508</td> <td>    0.004</td> <td>   11.690</td> <td> 0.000</td> <td>    0.042</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mnth[T.Nov]</th>                   <td>    0.2845</td> <td>    0.005</td> <td>   61.782</td> <td> 0.000</td> <td>    0.276</td> <td>    0.294</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mnth[T.Oct]</th>                   <td>    0.2667</td> <td>    0.004</td> <td>   61.683</td> <td> 0.000</td> <td>    0.258</td> <td>    0.275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mnth[T.Sept]</th>                  <td>   -0.0065</td> <td>    0.004</td> <td>   -1.473</td> <td> 0.141</td> <td>   -0.015</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weathersit[T.cloudy/misty]</th>    <td>   -0.0308</td> <td>    0.002</td> <td>  -14.233</td> <td> 0.000</td> <td>   -0.035</td> <td>   -0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weathersit[T.heavy rain/snow]</th> <td>   -0.6455</td> <td>    0.167</td> <td>   -3.871</td> <td> 0.000</td> <td>   -0.972</td> <td>   -0.319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weathersit[T.light rain/snow]</th> <td>   -0.4728</td> <td>    0.004</td> <td> -116.934</td> <td> 0.000</td> <td>   -0.481</td> <td>   -0.465</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hr</th>                            <td>    0.0507</td> <td>    0.000</td> <td>  351.836</td> <td> 0.000</td> <td>    0.050</td> <td>    0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>workingday</th>                    <td>   -0.0128</td> <td>    0.002</td> <td>   -6.573</td> <td> 0.000</td> <td>   -0.017</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>temp</th>                          <td>    2.5639</td> <td>    0.010</td> <td>  257.622</td> <td> 0.000</td> <td>    2.544</td> <td>    2.583</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                 bikers   No. Observations:                 8645\n",
       "Model:                            GLM   Df Residuals:                     8627\n",
       "Model Family:                 Poisson   Df Model:                           17\n",
       "Link Function:                    Log   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:            -3.4404e+05\n",
       "Date:                Wed, 14 Sep 2022   Deviance:                   6.3504e+05\n",
       "Time:                        11:14:35   Pearson chi2:                 6.83e+05\n",
       "No. Iterations:                     5   Pseudo R-squ. (CS):              1.000\n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================================\n",
       "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------\n",
       "Intercept                         3.0118      0.006    476.777      0.000       2.999       3.024\n",
       "mnth[T.Aug]                      -0.2288      0.005    -48.719      0.000      -0.238      -0.220\n",
       "mnth[T.Dec]                       0.2981      0.005     59.511      0.000       0.288       0.308\n",
       "mnth[T.Feb]                      -0.1015      0.006    -17.160      0.000      -0.113      -0.090\n",
       "mnth[T.Jan]                      -0.1450      0.007    -21.388      0.000      -0.158      -0.132\n",
       "mnth[T.July]                     -0.3777      0.005    -76.183      0.000      -0.387      -0.368\n",
       "mnth[T.June]                     -0.1502      0.005    -32.493      0.000      -0.159      -0.141\n",
       "mnth[T.March]                    -0.0312      0.005     -5.833      0.000      -0.042      -0.021\n",
       "mnth[T.May]                       0.0508      0.004     11.690      0.000       0.042       0.059\n",
       "mnth[T.Nov]                       0.2845      0.005     61.782      0.000       0.276       0.294\n",
       "mnth[T.Oct]                       0.2667      0.004     61.683      0.000       0.258       0.275\n",
       "mnth[T.Sept]                     -0.0065      0.004     -1.473      0.141      -0.015       0.002\n",
       "weathersit[T.cloudy/misty]       -0.0308      0.002    -14.233      0.000      -0.035      -0.027\n",
       "weathersit[T.heavy rain/snow]    -0.6455      0.167     -3.871      0.000      -0.972      -0.319\n",
       "weathersit[T.light rain/snow]    -0.4728      0.004   -116.934      0.000      -0.481      -0.465\n",
       "hr                                0.0507      0.000    351.836      0.000       0.050       0.051\n",
       "workingday                       -0.0128      0.002     -6.573      0.000      -0.017      -0.009\n",
       "temp                              2.5639      0.010    257.622      0.000       2.544       2.583\n",
       "=================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_bikeshare.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107.73434730516983"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we do another quick look at the training RMSE \n",
    "# to judge whether model is better, we would do train/validation split and check the model performance on the validation set.\n",
    "np.sqrt(((glm_bikeshare.fittedvalues - Bikeshare.bikers)**2).sum()/len(Bikeshare.bikers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7.8 An Application to Caravan Insurance Data \n",
    "This section is removed from the 2nd edition, but keep it as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Caravan = pd.read_csv('https://raw.githubusercontent.com/tvanzyl/Sharing_ISL_python/master/data/Caravan.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5822, 86)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Caravan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MOSTYPE</th>\n",
       "      <th>MAANTHUI</th>\n",
       "      <th>MGEMOMV</th>\n",
       "      <th>MGEMLEEF</th>\n",
       "      <th>MOSHOOFD</th>\n",
       "      <th>MGODRK</th>\n",
       "      <th>MGODPR</th>\n",
       "      <th>MGODOV</th>\n",
       "      <th>MGODGE</th>\n",
       "      <th>MRELGE</th>\n",
       "      <th>...</th>\n",
       "      <th>APERSONG</th>\n",
       "      <th>AGEZONG</th>\n",
       "      <th>AWAOREG</th>\n",
       "      <th>ABRAND</th>\n",
       "      <th>AZEILPL</th>\n",
       "      <th>APLEZIER</th>\n",
       "      <th>AFIETS</th>\n",
       "      <th>AINBOED</th>\n",
       "      <th>ABYSTAND</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MOSTYPE  MAANTHUI  MGEMOMV  MGEMLEEF  MOSHOOFD  MGODRK  MGODPR  MGODOV  \\\n",
       "0       33         1        3         2         8       0       5       1   \n",
       "1       37         1        2         2         8       1       4       1   \n",
       "2       37         1        2         2         8       0       4       2   \n",
       "3        9         1        3         3         3       2       3       2   \n",
       "4       40         1        4         2        10       1       4       1   \n",
       "\n",
       "   MGODGE  MRELGE  ...  APERSONG  AGEZONG  AWAOREG  ABRAND  AZEILPL  APLEZIER  \\\n",
       "0       3       7  ...         0        0        0       1        0         0   \n",
       "1       4       6  ...         0        0        0       1        0         0   \n",
       "2       4       3  ...         0        0        0       1        0         0   \n",
       "3       4       5  ...         0        0        0       1        0         0   \n",
       "4       4       7  ...         0        0        0       1        0         0   \n",
       "\n",
       "   AFIETS  AINBOED  ABYSTAND  Purchase  \n",
       "0       0        0         0        No  \n",
       "1       0        0         0        No  \n",
       "2       0        0         0        No  \n",
       "3       0        0         0        No  \n",
       "4       0        0         0        No  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Caravan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MOSTYPE</th>\n",
       "      <th>MAANTHUI</th>\n",
       "      <th>MGEMOMV</th>\n",
       "      <th>MGEMLEEF</th>\n",
       "      <th>MOSHOOFD</th>\n",
       "      <th>MGODRK</th>\n",
       "      <th>MGODPR</th>\n",
       "      <th>MGODOV</th>\n",
       "      <th>MGODGE</th>\n",
       "      <th>MRELGE</th>\n",
       "      <th>...</th>\n",
       "      <th>ALEVEN</th>\n",
       "      <th>APERSONG</th>\n",
       "      <th>AGEZONG</th>\n",
       "      <th>AWAOREG</th>\n",
       "      <th>ABRAND</th>\n",
       "      <th>AZEILPL</th>\n",
       "      <th>APLEZIER</th>\n",
       "      <th>AFIETS</th>\n",
       "      <th>AINBOED</th>\n",
       "      <th>ABYSTAND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24.253349</td>\n",
       "      <td>1.110615</td>\n",
       "      <td>2.678805</td>\n",
       "      <td>2.991240</td>\n",
       "      <td>5.773617</td>\n",
       "      <td>0.696496</td>\n",
       "      <td>4.626932</td>\n",
       "      <td>1.069907</td>\n",
       "      <td>3.258502</td>\n",
       "      <td>6.183442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076606</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>0.004638</td>\n",
       "      <td>0.570079</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.006012</td>\n",
       "      <td>0.031776</td>\n",
       "      <td>0.007901</td>\n",
       "      <td>0.014256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.846706</td>\n",
       "      <td>0.405842</td>\n",
       "      <td>0.789835</td>\n",
       "      <td>0.814589</td>\n",
       "      <td>2.856760</td>\n",
       "      <td>1.003234</td>\n",
       "      <td>1.715843</td>\n",
       "      <td>1.017503</td>\n",
       "      <td>1.597647</td>\n",
       "      <td>1.909482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377569</td>\n",
       "      <td>0.072782</td>\n",
       "      <td>0.080532</td>\n",
       "      <td>0.077403</td>\n",
       "      <td>0.562058</td>\n",
       "      <td>0.022696</td>\n",
       "      <td>0.081632</td>\n",
       "      <td>0.210986</td>\n",
       "      <td>0.090463</td>\n",
       "      <td>0.119996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           MOSTYPE     MAANTHUI      MGEMOMV     MGEMLEEF     MOSHOOFD  \\\n",
       "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000   \n",
       "mean     24.253349     1.110615     2.678805     2.991240     5.773617   \n",
       "std      12.846706     0.405842     0.789835     0.814589     2.856760   \n",
       "min       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "25%      10.000000     1.000000     2.000000     2.000000     3.000000   \n",
       "50%      30.000000     1.000000     3.000000     3.000000     7.000000   \n",
       "75%      35.000000     1.000000     3.000000     3.000000     8.000000   \n",
       "max      41.000000    10.000000     5.000000     6.000000    10.000000   \n",
       "\n",
       "            MGODRK       MGODPR       MGODOV       MGODGE       MRELGE  ...  \\\n",
       "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000  ...   \n",
       "mean      0.696496     4.626932     1.069907     3.258502     6.183442  ...   \n",
       "std       1.003234     1.715843     1.017503     1.597647     1.909482  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     4.000000     0.000000     2.000000     5.000000  ...   \n",
       "50%       0.000000     5.000000     1.000000     3.000000     6.000000  ...   \n",
       "75%       1.000000     6.000000     2.000000     4.000000     7.000000  ...   \n",
       "max       9.000000     9.000000     5.000000     9.000000     9.000000  ...   \n",
       "\n",
       "            ALEVEN     APERSONG      AGEZONG      AWAOREG       ABRAND  \\\n",
       "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000   \n",
       "mean      0.076606     0.005325     0.006527     0.004638     0.570079   \n",
       "std       0.377569     0.072782     0.080532     0.077403     0.562058   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "max       8.000000     1.000000     1.000000     2.000000     7.000000   \n",
       "\n",
       "           AZEILPL     APLEZIER       AFIETS      AINBOED     ABYSTAND  \n",
       "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000  \n",
       "mean      0.000515     0.006012     0.031776     0.007901     0.014256  \n",
       "std       0.022696     0.081632     0.210986     0.090463     0.119996  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "max       1.000000     2.000000     3.000000     2.000000     2.000000  \n",
       "\n",
       "[8 rows x 85 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Caravan.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale of the variables matters in KNN ! The core question in KNN is how to define proper distance metric. \n",
    "Because the KNN classifier predicts the class of a given test observation by identifying the observations \n",
    "that are nearest to it, the scale of the variables matters. Any variables that are on a large scale will \n",
    "have a much larger effect on the distance between the observations, and hence on the KNN classifier, \n",
    "than variables that are on a small scale. For instance, imagine a data set that contains two variables, \n",
    "salary and age (measured in dollars and years, respectively). As far as KNN is concerned, \n",
    "a difference of 1,000 in salary is enormous compared to a difference of 50 years in age. \n",
    "Consequently, salary will drive the KNN classification results, and age will have almost no effect. \n",
    "This is contrary to our intuition that a salary difference of 1, 000 is quite small compared to an age difference of 50 years. \n",
    "Furthermore, the importance of scale to the KNN classifier leads to another issue: if we measured salary in Japanese yen, \n",
    "or if we measured age in minutes, then we’d get quite different classification results from what we get \n",
    "if these two variables are measured in dollars and years. \n",
    "\n",
    "A good (debatable) way to handle this problem is to standardize the data so that all standardize \n",
    "variables are given a mean of zero and a standard deviation of one. Then all variables will be on a comparable scale.\n",
    "The scale() function does just scale() this. In standardizing the data, we exclude column 86, \n",
    "because that is the qualitative Purchase variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_label = pd.DataFrame(np.zeros(shape=(Caravan.shape[0],1)), columns = ['label'])\n",
    "predict_label[Caravan['Purchase'] == 'Yes'] = 1\n",
    "Caravan_drop = Caravan.drop(labels='Purchase', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I took a slightly different approach from the book. \n",
    "The training and testing data were splited by index. \n",
    "The normalization was done on the train set. \n",
    "Afterwards, the same normalization was applied to validate test. \n",
    "The code might seem wordy, but it helps clear the logical flow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I took a slightly different approach from the book. The training and testing data were splited by index. \n",
    "# the normalization was done on the train set. Afterwards, the same normalization was applied to validate test.  \n",
    "# the code might seem wordy, but it helps clear the logical flow. \n",
    "train_size = 1000\n",
    "train_index = range(0, train_size)\n",
    "X_validate = Caravan_drop.iloc[train_index, ]\n",
    "Y_validate = predict_label.iloc[train_index, ]\n",
    "X_train = Caravan_drop.iloc[train_size:, ]\n",
    "Y_train = predict_label.iloc[train_size:, ]\n",
    "\n",
    "\n",
    "X_train_scaled = preprocessing.scale(X_train)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_validate_scaled = scaler.transform(X_validate)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.883\n",
      "[[874  67]\n",
      " [ 50   9]]\n"
     ]
    }
   ],
   "source": [
    "# train with 1 neighbor \n",
    "n_neighbors = 1\n",
    "neigh = KNN(n_neighbors= n_neighbors) # use n_neighbors to change the # of tune the performance of KNN\n",
    "KNN_fit = neigh.fit(X_train_scaled, Y_train.iloc[:,0]) #learning the projection matrix\n",
    "X_validate_labels=KNN_fit.predict(X_validate_scaled)\n",
    "X_validate_prob = KNN_fit.predict_proba(X_validate_scaled) \n",
    "print(np.mean(Y_validate.iloc[:,0]==X_validate_labels))\n",
    "print(confusion_matrix(Y_validate.iloc[:,0], X_validate_labels))\n",
    "\n",
    "# the rest of this exercise considers all the trade-off between False postive and False negative.  \n",
    "# the concept of accuracy is NOT always the golden metric for classification problems. \n",
    "# precision and recall, sensitivity and specificity, F1 score... are all reasonable metrics to consider. \n",
    "# we will discuss more on the concept of trainning, validation and test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of Chapter 4"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.10.4 ('jupyter')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "092633841fae5a453d59f3730329b400a8541b45bc6f2e0a3e6c2e0778ee7c3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
